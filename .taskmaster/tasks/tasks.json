{
  "master": {
    "tasks": [
      {
        "id": 11,
        "title": "Add SEO Component to ForConsumers.tsx and ForBusinesses.tsx",
        "description": "Implement SEO component with unique title, description, and canonical URL for the first two pages requiring SEO metadata.",
        "details": "Import SEO from '@/components/SEO'; Add <SEO title=\"For Consumers | Mesa Group Consulting\" description=\"Discover personalized credit building solutions for consumers with Mesa Group Consulting's expert guidance and tools.\" canonicalUrl=\"/for-consumers\" /> inside the component return statement. Ensure title is 50-60 chars, description 150-160 chars with natural keywords.",
        "testStrategy": "Build site, navigate to /for-consumers and /for-businesses, inspect page source to verify unique title, meta description, canonical URL, OG tags present and correct. Check View Page Source vs rendered DOM.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Import SEO component in ForConsumers.tsx and ForBusinesses.tsx",
            "description": "Add the import statement for the SEO component at the top of both ForConsumers.tsx and ForBusinesses.tsx files.",
            "dependencies": [],
            "details": "Add 'import SEO from '@/components/SEO';' at the top of both files after other imports. Verify the path is correct and matches the project structure.",
            "status": "done",
            "testStrategy": "Verify no TypeScript/import errors appear in IDE and build process completes successfully.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:51.913Z"
          },
          {
            "id": 2,
            "title": "Add SEO component to ForConsumers.tsx with metadata",
            "description": "Insert the SEO component with title, description, and canonical URL optimized for the For Consumers page.",
            "dependencies": [
              1
            ],
            "details": "Add <SEO title=\"For Consumers | Mesa Group Consulting\" description=\"Discover personalized credit building solutions for consumers with Mesa Group Consulting's expert guidance and tools.\" canonicalUrl=\"/for-consumers\" /> inside the component return statement, preferably at the top before other JSX elements. Verify title is 50-60 chars and description is 150-160 chars.",
            "status": "done",
            "testStrategy": "Navigate to /for-consumers, inspect page source to verify title tag, meta description, canonical link, and Open Graph tags are present and correct.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:51.924Z"
          },
          {
            "id": 3,
            "title": "Add SEO component to ForBusinesses.tsx with metadata",
            "description": "Insert the SEO component with unique title, description, and canonical URL tailored for the For Businesses page.",
            "dependencies": [
              1
            ],
            "details": "Add <SEO title=\"For Businesses | Mesa Group Consulting\" description=\"Empower your business with comprehensive credit building solutions and expert consulting services from Mesa Group Consulting.\" canonicalUrl=\"/for-businesses\" /> inside the component return statement. Ensure unique content that differentiates from consumer page, with title 50-60 chars and description 150-160 chars.",
            "status": "done",
            "testStrategy": "Navigate to /for-businesses, inspect page source to verify unique title tag, meta description, canonical link, and Open Graph tags differ from ForConsumers page.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:51.931Z"
          },
          {
            "id": 4,
            "title": "Build and verify SEO metadata rendering in browser",
            "description": "Build the application and test both pages in browser to ensure SEO metadata renders correctly in page source.",
            "dependencies": [
              2,
              3
            ],
            "details": "Run production build command, start local server or deploy to preview environment. Navigate to both /for-consumers and /for-businesses pages. Use 'View Page Source' (not just inspect element) to verify meta tags are in the initial HTML response, not just client-side rendered.",
            "status": "done",
            "testStrategy": "Check View Page Source for both pages to confirm title, meta description, canonical URL, og:title, og:description, and og:url tags are present with correct values. Compare rendered DOM vs initial HTML source.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:51.938Z"
          },
          {
            "id": 5,
            "title": "Validate SEO implementation meets specifications",
            "description": "Final validation that all SEO requirements are met including character counts, keyword usage, and proper formatting.",
            "dependencies": [
              4
            ],
            "details": "Verify title tags are exactly 50-60 characters, descriptions are 150-160 characters with natural keyword integration. Confirm both pages have unique metadata, canonical URLs are correct (/for-consumers and /for-businesses), and all tags follow the established pattern with ' | Mesa Group Consulting' suffix.",
            "status": "done",
            "testStrategy": "Use SEO validation tools or manual character count to verify length requirements. Test canonical URLs resolve correctly. Ensure no duplicate content between the two pages.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:51.945Z"
          }
        ],
        "complexity": 2,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed - simple component addition.",
        "updatedAt": "2026-02-09T21:35:51.945Z"
      },
      {
        "id": 12,
        "title": "Add SEO Component to BuildCredit.tsx and BusinessCreditBuilder.tsx",
        "description": "Roll out SEO metadata to credit builder pages using existing react-helmet-async pattern.",
        "details": "Add SEO component: <SEO title=\"Build Credit Fast | Mesa Group Consulting\" description=\"Learn proven strategies to build credit quickly with our step-by-step guides, calculators, and expert advice from Mesa Group Consulting.\" canonicalUrl=\"/build-credit\" />. Create unique descriptions targeting credit building keywords.",
        "testStrategy": "Deploy to Vercel preview, use browser dev tools to verify meta tags render correctly, test OG tags with Facebook Sharing Debugger.",
        "priority": "high",
        "dependencies": [
          "11"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Import SEO component in BuildCredit.tsx",
            "description": "Add the SEO component import statement at the top of the BuildCredit.tsx file to enable SEO metadata functionality.",
            "dependencies": [],
            "details": "Add 'import SEO from '@/components/SEO';' to the imports section of BuildCredit.tsx. Verify the import path matches the project structure and that the SEO component is available from the previous task 11 implementation.",
            "status": "done",
            "testStrategy": "Verify no TypeScript/import errors in the IDE and that the file compiles successfully without errors.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:53.290Z"
          },
          {
            "id": 2,
            "title": "Add SEO component to BuildCredit.tsx return statement",
            "description": "Insert the SEO component with credit building metadata inside the BuildCredit.tsx component's return statement.",
            "dependencies": [
              1
            ],
            "details": "Add <SEO title=\"Build Credit Fast | Mesa Group Consulting\" description=\"Learn proven strategies to build credit quickly with our step-by-step guides, calculators, and expert advice from Mesa Group Consulting.\" canonicalUrl=\"/build-credit\" /> at the beginning of the component's JSX return. Ensure proper placement and formatting.",
            "status": "done",
            "testStrategy": "Build the application and navigate to /build-credit route. Inspect page source to verify title, meta description, and canonical URL are present and correct.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:53.298Z"
          },
          {
            "id": 3,
            "title": "Import SEO component in BusinessCreditBuilder.tsx",
            "description": "Add the SEO component import statement at the top of the BusinessCreditBuilder.tsx file to enable SEO metadata functionality.",
            "dependencies": [],
            "details": "Add 'import SEO from '@/components/SEO';' to the imports section of BusinessCreditBuilder.tsx. Verify the import path matches the project structure and follows the same pattern as BuildCredit.tsx.",
            "status": "done",
            "testStrategy": "Verify no TypeScript/import errors in the IDE and that the file compiles successfully without errors.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:53.305Z"
          },
          {
            "id": 4,
            "title": "Add SEO component to BusinessCreditBuilder.tsx with unique metadata",
            "description": "Insert the SEO component with business credit building specific metadata inside the BusinessCreditBuilder.tsx component's return statement.",
            "dependencies": [
              3
            ],
            "details": "Add <SEO title=\"Business Credit Builder | Mesa Group Consulting\" description=\"Build strong business credit with expert strategies, tools, and guidance from Mesa Group Consulting. Establish and grow your business creditworthiness.\" canonicalUrl=\"/business-credit-builder\" /> at the beginning of the component's JSX return. Create unique description targeting business credit keywords while maintaining 150-160 character length.",
            "status": "done",
            "testStrategy": "Build the application and navigate to /business-credit-builder route. Inspect page source to verify title, meta description, and canonical URL are present, unique, and correct.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:53.313Z"
          },
          {
            "id": 5,
            "title": "Deploy and verify SEO metadata on both pages",
            "description": "Deploy changes to Vercel preview environment and comprehensively test SEO metadata rendering on both BuildCredit and BusinessCreditBuilder pages.",
            "dependencies": [
              2,
              4
            ],
            "details": "Deploy to Vercel preview environment. Use browser dev tools to inspect meta tags on both /build-credit and /business-credit-builder routes. Verify title tags, meta descriptions, canonical URLs, and Open Graph tags render correctly. Test OG tags using Facebook Sharing Debugger to ensure proper social media preview functionality.",
            "status": "done",
            "testStrategy": "Check View Page Source vs rendered DOM for both pages. Validate all meta tags are present and unique. Use Facebook Sharing Debugger and Twitter Card Validator to verify OG tags display correctly for social sharing.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:53.320Z"
          }
        ],
        "complexity": 2,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed - identical to task 11 pattern.",
        "updatedAt": "2026-02-09T21:35:53.320Z"
      },
      {
        "id": 13,
        "title": "Implement SEO for Resources, ArticlesInsights, and FinancialCalculators.tsx",
        "description": "Add SEO metadata to resource and calculator pages with service-specific keywords.",
        "details": "For Resources.tsx: title=\"Free Credit Resources | Mesa Group Consulting\", description with keywords like credit tools, guides, calculators. Ensure canonical URLs match routes. Use existing SEO component props exactly as specified in PRD.",
        "testStrategy": "Run `npm run build`, verify no console errors, check generated HTML in dist/ folder for meta injection, test page load with JavaScript disabled.",
        "priority": "high",
        "dependencies": [
          "12"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add SEO component to Resources.tsx with metadata",
            "description": "Import and implement SEO component in Resources.tsx with title, description, and canonical URL targeting credit resource keywords.",
            "dependencies": [],
            "details": "Import SEO from '@/components/SEO'. Add <SEO title=\"Free Credit Resources | Mesa Group Consulting\" description=\"Access free credit tools, guides, and calculators to improve your financial health with Mesa Group Consulting's comprehensive resources.\" canonicalUrl=\"/resources\" /> at the top of the component return statement. Ensure description is 150-160 characters and includes keywords: credit tools, guides, calculators.",
            "status": "done",
            "testStrategy": "Verify SEO component renders without errors, inspect page source to confirm meta tags are present with correct values.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:54.740Z"
          },
          {
            "id": 2,
            "title": "Add SEO component to ArticlesInsights.tsx with metadata",
            "description": "Import and implement SEO component in ArticlesInsights.tsx with unique title, description, and canonical URL for articles and insights content.",
            "dependencies": [],
            "details": "Import SEO from '@/components/SEO'. Add <SEO title=\"Articles & Insights | Mesa Group Consulting\" description=\"Read expert articles and insights on credit building, financial planning, and debt management from Mesa Group Consulting's team of professionals.\" canonicalUrl=\"/articles-insights\" /> at the top of the component return statement. Ensure title is 50-60 characters and description is 150-160 characters with relevant keywords.",
            "status": "done",
            "testStrategy": "Check component renders correctly, validate meta tags in page source match specified values.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:54.746Z"
          },
          {
            "id": 3,
            "title": "Add SEO component to FinancialCalculators.tsx with metadata",
            "description": "Import and implement SEO component in FinancialCalculators.tsx with calculator-specific keywords and proper canonical URL.",
            "dependencies": [],
            "details": "Import SEO from '@/components/SEO'. Add <SEO title=\"Financial Calculators | Mesa Group Consulting\" description=\"Use free financial calculators for credit scores, loan payments, and debt payoff planning from Mesa Group Consulting in Bakersfield, CA.\" canonicalUrl=\"/financial-calculators\" /> at the top of the component return statement. Ensure keywords include: calculators, credit scores, loan payments, debt payoff.",
            "status": "done",
            "testStrategy": "Verify SEO component integration, inspect rendered HTML for correct meta tags and canonical URL.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:54.752Z"
          },
          {
            "id": 4,
            "title": "Verify canonical URLs match exact route paths",
            "description": "Cross-check that all three canonical URLs specified in SEO components exactly match their corresponding route definitions in the application.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Review routing configuration and verify: Resources.tsx canonicalUrl=\"/resources\", ArticlesInsights.tsx canonicalUrl=\"/articles-insights\", FinancialCalculators.tsx canonicalUrl=\"/financial-calculators\". Ensure no trailing slashes, correct casing, and paths match exactly what's defined in the router. Check for any route aliases or redirects that might affect canonical URL accuracy.",
            "status": "done",
            "testStrategy": "Navigate to each page in browser, check network tab for correct URL paths, verify canonical link tags in page source point to exact current URLs.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:54.758Z"
          },
          {
            "id": 5,
            "title": "Build and validate SEO meta injection in production output",
            "description": "Run production build and verify SEO metadata is correctly injected into generated HTML files without console errors.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Execute `npm run build` and monitor console for any errors or warnings. Navigate to dist/ folder and inspect generated HTML files for Resources, ArticlesInsights, and FinancialCalculators pages. Verify meta tags (title, description, canonical, OG tags) are present in static HTML. Test page load with JavaScript disabled to ensure meta tags are server-rendered or statically generated.",
            "status": "done",
            "testStrategy": "Run `npm run build`, verify no console errors, check generated HTML in dist/ folder for meta injection, test page load with JavaScript disabled to confirm SEO tags are accessible to crawlers.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:54.763Z"
          }
        ],
        "complexity": 3,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed - consistent SEO component pattern across 3 files.",
        "updatedAt": "2026-02-09T21:35:54.763Z"
      },
      {
        "id": 14,
        "title": "Complete SEO Rollout for Credit Services Pages (Monitoring to DebtRelief)",
        "description": "Add SEO to 7 credit service pages: CreditMonitoring.tsx through DebtRelief.tsx.",
        "details": "Batch implement SEO with unique descriptions: e.g., CreditMonitoring: \"Monitor credit scores daily with Mesa Group Consulting's affordable monitoring services and alerts.\" Ensure all titles end with \" | Mesa Group Consulting\", canonicals correct.",
        "testStrategy": "Create test script to fetch all pages and validate meta tags using Puppeteer, verify 100% coverage of listed pages.",
        "priority": "high",
        "dependencies": [
          "13"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement SEO for first 4 credit service pages (CreditMonitoring to midpoint)",
            "description": "Add SEO metadata to the first 4 credit service pages: CreditMonitoring.tsx, CreditRepair.tsx, CreditBuilder.tsx, and CreditCounseling.tsx with unique descriptions and proper title formatting.",
            "dependencies": [
              13
            ],
            "details": "Implement <SEO> component for each page with unique descriptions. Example: CreditMonitoring: 'Monitor credit scores daily with Mesa Group Consulting's affordable monitoring services and alerts.' Ensure all titles follow pattern '[Service Name] | Mesa Group Consulting' and canonicalUrl matches route path. Verify no duplicate descriptions across pages.",
            "status": "done",
            "testStrategy": "Manual verification of meta tags in browser DevTools for each of the 4 pages. Check title format, description uniqueness, and canonical URL correctness.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:35:55.855Z"
          }
        ],
        "complexity": 4,
        "recommendedSubtasks": 1,
        "expansionPrompt": "Break into two subtasks: 1) Implement SEO for first 4 credit service pages (CreditMonitoring to [midpoint]), 2) Implement remaining 3 pages with final validation script.",
        "updatedAt": "2026-02-09T21:35:55.855Z"
      },
      {
        "id": 15,
        "title": "SEO Implementation for Loan and Funding Pages",
        "description": "Add SEO metadata to 8 financial product pages from CreditCards.tsx to BusinessDebtRelief.tsx.",
        "details": "Target keywords like personal loans, business funding: <SEO title=\"Personal Loans | Mesa Group Consulting\" description=\"Compare personal loan options and rates with expert guidance from Mesa Group Consulting in Bakersfield, CA.\" canonicalUrl=\"/personal-loans\" />.",
        "testStrategy": "Lighthouse SEO audit on staging, target 90+ score, verify unique titles/descriptions across all pages using SEO checker tools.",
        "priority": "high",
        "dependencies": [
          "14"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add SEO metadata to personal loan and credit card pages (4 pages)",
            "description": "Implement SEO component with targeted keywords for CreditCards.tsx, PersonalLoans.tsx, and 2 other consumer financial product pages.",
            "dependencies": [
              14
            ],
            "details": "Add SEO component to 4 consumer-focused pages (CreditCards.tsx, PersonalLoans.tsx, and 2 related pages). Use keyword-rich titles and descriptions following the pattern: <SEO title=\"[Product] | Mesa Group Consulting\" description=\"Compare [product] options and rates with expert guidance from Mesa Group Consulting in Bakersfield, CA.\" canonicalUrl=\"/[product-route]\" />. Ensure unique titles and descriptions for each page targeting keywords like personal loans, credit cards, consumer financing.",
            "status": "done",
            "testStrategy": "Verify SEO meta tags render correctly in browser dev tools, check unique titles/descriptions using SEO checker tools, validate canonical URLs match routes.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:37:07.356Z"
          },
          {
            "id": 2,
            "title": "Add SEO metadata to business funding pages and run Lighthouse audit",
            "description": "Implement SEO for 4 business-focused pages (BusinessDebtRelief.tsx and 3 others) and perform comprehensive Lighthouse SEO audit targeting 90+ score.",
            "dependencies": [
              1
            ],
            "details": "Add SEO component to 4 business funding pages including BusinessDebtRelief.tsx with business-focused keywords like business funding, business loans, debt relief. Follow same SEO component pattern with unique metadata. After implementation, run Lighthouse SEO audit on staging environment for all 8 pages (4 personal + 4 business). Target 90+ SEO score, verify performance metrics, check for duplicate content issues, validate structured data, and ensure all meta tags are properly indexed.",
            "status": "done",
            "testStrategy": "Run Lighthouse SEO audit on staging for all 8 pages targeting 90+ score, use SEO checker tools to verify no duplicate titles/descriptions across pages, test page load performance, validate canonical URLs and meta tag injection in generated HTML.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:38:08.032Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 2,
        "expansionPrompt": "Split into: 1) Personal loan/credit card pages (4 pages), 2) Business funding pages (4 pages), 3) Lighthouse SEO audit and validation.",
        "updatedAt": "2026-02-09T21:38:08.032Z"
      },
      {
        "id": 16,
        "title": "SEO for News, Contact, Legal, and 404 Pages",
        "description": "Complete SEO rollout for remaining pages: MesaNews.tsx, Contact.tsx, TermsAndConditions.tsx, NotFound.tsx.",
        "details": "404 page: title=\"Page Not Found | Mesa Group Consulting\", description=\"The page you're looking for doesn't exist. Discover our credit building services.\" canonicalUrl=\"/404\". Ensure helpful 404 meta.",
        "testStrategy": "Test 404 page accessibility, verify robots.txt allows crawling, check meta renders on direct URL access.",
        "priority": "high",
        "dependencies": [
          "15"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement SEO metadata for MesaNews.tsx page",
            "description": "Add SEO component with appropriate title, description, and canonical URL to the MesaNews.tsx page to optimize for news and updates content.",
            "dependencies": [],
            "details": "Add <SEO title=\"News & Updates | Mesa Group Consulting\" description=\"Stay informed with the latest news, updates, and insights from Mesa Group Consulting's credit building and financial services.\" canonicalUrl=\"/news\" /> to MesaNews.tsx. Ensure the SEO component is imported and placed at the top of the component return statement.",
            "status": "done",
            "testStrategy": "Verify meta tags render correctly in browser dev tools, check that title appears in browser tab, validate canonical URL matches route path.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:41:31.479Z"
          },
          {
            "id": 2,
            "title": "Implement SEO metadata for Contact.tsx page",
            "description": "Add SEO component with contact-focused keywords and metadata to the Contact.tsx page to improve discoverability for users seeking to reach Mesa Group Consulting.",
            "dependencies": [],
            "details": "Add <SEO title=\"Contact Us | Mesa Group Consulting\" description=\"Get in touch with Mesa Group Consulting in Bakersfield, CA. Contact our credit building experts for personalized financial guidance and support.\" canonicalUrl=\"/contact\" /> to Contact.tsx. Include location-based keywords for local SEO optimization.",
            "status": "done",
            "testStrategy": "Test page rendering with SEO tags, verify local keywords are present in description, check meta tags using browser inspector and SEO validation tools.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:41:42.791Z"
          },
          {
            "id": 3,
            "title": "Implement SEO metadata for TermsAndConditions.tsx page",
            "description": "Add SEO component to TermsAndConditions.tsx with appropriate legal page metadata to ensure proper indexing and user expectations.",
            "dependencies": [],
            "details": "Add <SEO title=\"Terms and Conditions | Mesa Group Consulting\" description=\"Read Mesa Group Consulting's terms and conditions for our credit building and financial services. Understand your rights and our policies.\" canonicalUrl=\"/terms-and-conditions\" /> to TermsAndConditions.tsx. Ensure clear, professional description for legal content.",
            "status": "done",
            "testStrategy": "Validate meta tags render correctly, verify canonical URL matches route, check that description accurately represents legal content nature.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:41:57.498Z"
          },
          {
            "id": 4,
            "title": "Implement SEO metadata for NotFound.tsx (404 page) with helpful error page best practices",
            "description": "Add SEO component to NotFound.tsx following 404 error page SEO best practices with helpful messaging and service discovery prompts.",
            "dependencies": [],
            "details": "Add <SEO title=\"Page Not Found | Mesa Group Consulting\" description=\"The page you're looking for doesn't exist. Discover our credit building services.\" canonicalUrl=\"/404\" /> to NotFound.tsx. Implement helpful 404 meta that guides users back to services. Consider adding noindex meta tag to prevent 404 pages from being indexed while maintaining helpful user experience.",
            "status": "done",
            "testStrategy": "Test 404 page accessibility by navigating to non-existent URLs, verify robots.txt allows crawling, check meta renders on direct URL access, validate that 404 returns proper HTTP status code while displaying helpful content.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:42:11.139Z"
          },
          {
            "id": 5,
            "title": "Comprehensive testing and validation of all four pages SEO implementation",
            "description": "Perform end-to-end testing of SEO metadata across MesaNews, Contact, TermsAndConditions, and NotFound pages to ensure consistency and correctness.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Run `npm run build` and verify no console errors. Check generated HTML in dist/ folder for proper meta tag injection on all four pages. Use Lighthouse SEO audit to verify scores. Test each page with JavaScript disabled to ensure meta tags are server-rendered. Validate all titles end with ' | Mesa Group Consulting', descriptions are unique and keyword-optimized, and canonical URLs match their respective routes.",
            "status": "done",
            "testStrategy": "Create automated test script to validate meta tags across all four pages, run Lighthouse SEO audit targeting 90+ score, verify unique titles/descriptions using SEO checker tools, test 404 page specifically for proper HTTP status and helpful meta content.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:42:31.754Z"
          }
        ],
        "complexity": 3,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed - 4 standard pages with clear specifications.",
        "updatedAt": "2026-02-09T21:42:31.754Z"
      },
      {
        "id": 17,
        "title": "Update generate-sitemap.js to Include All Routes",
        "description": "Verify and update sitemap generation script to include all 30+ routes from App.tsx.",
        "details": "Review App.tsx routes, ensure generate-sitemap.js dynamically pulls all paths. Run `npm run build` to generate fresh sitemap.xml. Verify https://www.mesagroupconsulting.com/sitemap.xml accessible post-deploy.",
        "testStrategy": "curl sitemap.xml endpoint, validate XML structure with sitemap validator, confirm all 30+ pages listed with correct lastmod dates.",
        "priority": "high",
        "dependencies": [
          "16"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Extract and Configure All 30+ Routes from App.tsx in Sitemap Generator",
            "description": "Parse App.tsx to identify all React Router routes and update generate-sitemap.js to dynamically include all paths in the sitemap generation process.",
            "dependencies": [],
            "details": "Review App.tsx file to extract all route definitions (30+ routes). Update generate-sitemap.js script to programmatically read and include all routes. Ensure dynamic route handling for any parameterized paths. Configure proper URL structure with https://www.mesagroupconsulting.com base URL. Set appropriate priority and changefreq values for different route types.",
            "status": "done",
            "testStrategy": "Run generate-sitemap.js locally to produce sitemap.xml. Verify all 30+ routes are present in output. Check XML structure is valid using online XML validator. Confirm no duplicate URLs and all paths use correct domain.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:46:03.615Z"
          },
          {
            "id": 2,
            "title": "Build, Deploy and Validate Sitemap Accessibility",
            "description": "Execute npm run build to generate fresh sitemap.xml, deploy to production, and verify sitemap is accessible and properly formatted at the live URL.",
            "dependencies": [
              1
            ],
            "details": "Run `npm run build` command to trigger sitemap generation as part of build process. Verify sitemap.xml is created in public/build directory. Deploy updated code to production environment. Test sitemap accessibility at https://www.mesagroupconsulting.com/sitemap.xml. Validate lastmod dates are current and all 30+ routes appear with correct formatting.",
            "status": "done",
            "testStrategy": "Use curl to fetch https://www.mesagroupconsulting.com/sitemap.xml and verify 200 response. Validate XML structure using Google's sitemap validator or similar tool. Confirm all 30+ pages are listed with proper URL format, lastmod timestamps, and valid XML schema compliance.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:46:18.559Z"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 2,
        "expansionPrompt": "1) Extract all routes from App.tsx into sitemap generator, 2) Test sitemap generation and validate XML structure across all 30+ routes.",
        "updatedAt": "2026-02-09T21:46:18.559Z"
      },
      {
        "id": 18,
        "title": "Update public/robots.txt and Submit React Sitemap to GSC",
        "description": "Configure robots.txt with sitemap reference and submit to Google Search Console.",
        "details": "Update robots.txt: User-agent: * Allow: / Sitemap: https://www.mesagroupconsulting.com/sitemap.xml. Submit via GSC property www.mesagroupconsulting.com.",
        "testStrategy": "Verify robots.txt at /robots.txt, check GSC sitemap status shows 'Success', monitor Coverage report for new pages.",
        "priority": "high",
        "dependencies": [
          "17"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create or update public/robots.txt file with sitemap reference",
            "description": "Update the robots.txt file in the public directory to allow all user agents and reference the sitemap URL.",
            "dependencies": [],
            "details": "Navigate to the public folder in the React project. Create or edit robots.txt file with the following content:\nUser-agent: *\nAllow: /\nSitemap: https://www.mesagroupconsulting.com/sitemap.xml\n\nEnsure proper line breaks and formatting. Save the file and commit changes to version control.",
            "status": "done",
            "testStrategy": "After deployment, verify robots.txt is accessible at https://www.mesagroupconsulting.com/robots.txt. Check that content matches expected format and sitemap URL is correct.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:47:42.709Z"
          },
          {
            "id": 2,
            "title": "Verify sitemap.xml is accessible and properly formatted",
            "description": "Confirm that the sitemap.xml file generated by Task 17 is accessible at the expected URL and contains valid XML.",
            "dependencies": [],
            "details": "Access https://www.mesagroupconsulting.com/sitemap.xml in a browser. Verify the XML structure is valid and includes all expected routes from the React application. Use an online sitemap validator tool to check for any formatting issues or errors. Ensure lastmod dates are present and accurate.",
            "status": "done",
            "testStrategy": "Use curl or browser to fetch sitemap.xml. Validate XML structure using tools like xml-sitemaps.com validator. Confirm all 30+ routes are listed with proper URLs and metadata.",
            "parentId": "undefined",
            "updatedAt": "2026-02-09T21:47:43.814Z"
          },
          {
            "id": 3,
            "title": "Access Google Search Console for www.mesagroupconsulting.com property",
            "description": "Log into Google Search Console and navigate to the correct property for the main React website.",
            "dependencies": [],
            "details": "Go to https://search.google.com/search-console and sign in with the appropriate Google account that has access to the www.mesagroupconsulting.com property. Verify ownership is confirmed and the property is set up correctly. If property doesn't exist, add it using domain or URL prefix method and complete verification.",
            "status": "done",
            "testStrategy": "Confirm successful login to GSC. Verify the property www.mesagroupconsulting.com appears in the property selector and shows verified status.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T18:21:43.433Z"
          },
          {
            "id": 4,
            "title": "Submit sitemap.xml to Google Search Console",
            "description": "Add the sitemap URL to Google Search Console for the www.mesagroupconsulting.com property to enable Google crawling and indexing.",
            "dependencies": [
              2,
              3
            ],
            "details": "In Google Search Console, navigate to Sitemaps section in the left sidebar. Enter 'sitemap.xml' in the 'Add a new sitemap' field (full URL: https://www.mesagroupconsulting.com/sitemap.xml). Click Submit button. Wait for GSC to process the sitemap submission, which may take a few minutes to several hours.",
            "status": "done",
            "testStrategy": "Check GSC Sitemaps page shows the submitted sitemap with 'Success' status. Verify the number of discovered URLs matches expected count from sitemap. Monitor for any errors or warnings.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T18:21:43.463Z"
          },
          {
            "id": 5,
            "title": "Monitor GSC Coverage report and verify indexing progress",
            "description": "Review Google Search Console Coverage report to ensure pages from the sitemap are being discovered and indexed without errors.",
            "dependencies": [
              4
            ],
            "details": "After sitemap submission (wait 24-48 hours for initial processing), navigate to Coverage section in GSC. Check for any errors, warnings, or excluded pages. Verify that valid pages are increasing in count. Look for issues like 404s, duplicate content, or noindex tags that might prevent indexing. Document any issues found for resolution in Task 21.",
            "status": "done",
            "testStrategy": "GSC Coverage report shows increasing number of valid indexed pages. No critical errors related to sitemap URLs. Sitemap status remains 'Success' with no fetch errors. Cross-reference with sitemap.xml to ensure all important pages are being processed.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T18:21:43.471Z"
          }
        ],
        "complexity": 3,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed - simple config file + GSC submission.",
        "updatedAt": "2026-02-10T18:21:43.471Z"
      },
      {
        "id": 19,
        "title": "Configure WordPress Rank Math Sitemap and robots.txt",
        "description": "Verify Rank Math settings and ensure sitemap accessible at blog.mesagroupconsulting.com/sitemap_index.xml.",
        "details": "WordPress admin > Rank Math > Sitemap Settings: enable posts/pages, exclude author archives. Test post-sitemap.xml, page-sitemap.xml. Update robots.txt to reference sitemap_index.xml.",
        "testStrategy": "Access sitemap URLs directly, validate XML, use GSC Sitemaps tester before submission.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure Rank Math sitemap settings",
            "description": "Access WordPress admin panel and configure Rank Math plugin sitemap settings to enable posts and pages while excluding author archives.",
            "dependencies": [],
            "details": "Navigate to WordPress admin > Rank Math > Sitemap Settings. Enable sitemaps for posts and pages. Exclude author archives from sitemap generation. Verify sitemap_index.xml is accessible at blog.mesagroupconsulting.com/sitemap_index.xml. Test individual sitemap files including post-sitemap.xml and page-sitemap.xml to ensure they are generating correctly with proper XML structure.",
            "status": "done",
            "testStrategy": "Access sitemap URLs directly (sitemap_index.xml, post-sitemap.xml, page-sitemap.xml), validate XML structure using online validators, verify all enabled content types appear in index, use Google Search Console Sitemaps tester to validate before submission.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T16:52:54.493Z"
          }
        ],
        "complexity": 4,
        "recommendedSubtasks": 1,
        "expansionPrompt": "Split into: 1) Configure Rank Math sitemap settings, 2) Update WordPress robots.txt and validate all sitemap endpoints.",
        "updatedAt": "2026-02-10T16:52:54.493Z"
      },
      {
        "id": 20,
        "title": "WordPress Blog GSC Property Setup and Sitemap Submission",
        "description": "Add/verify blog.mesagroupconsulting.com in GSC and submit sitemap.",
        "details": "Add property in GSC, verify via DNS TXT or HTML file upload. Submit https://blog.mesagroupconsulting.com/sitemap_index.xml. Request indexing for posts.",
        "testStrategy": "Check GSC verification status, review Coverage report for errors, verify sitemap processed successfully.",
        "priority": "high",
        "dependencies": [
          "19"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add blog.mesagroupconsulting.com property in Google Search Console",
            "description": "Navigate to Google Search Console and add the blog subdomain as a new property using the URL prefix method.",
            "dependencies": [],
            "details": "Log into Google Search Console at search.google.com/search-console. Click 'Add Property' and select 'URL prefix' option. Enter https://blog.mesagroupconsulting.com as the property URL. Proceed to verification step selection.",
            "status": "done",
            "testStrategy": "Confirm property appears in GSC property selector dropdown and shows 'Unverified' status initially.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T17:01:05.753Z"
          },
          {
            "id": 2,
            "title": "Verify blog property ownership via DNS TXT record or HTML file upload",
            "description": "Complete GSC property verification using either DNS TXT record method or HTML file upload method to prove domain ownership.",
            "dependencies": [
              1
            ],
            "details": "Choose verification method: (Option A) DNS TXT - Add provided TXT record to domain DNS settings via hosting provider, wait 24-48 hours for propagation, click Verify in GSC. (Option B) HTML file - Download verification HTML file from GSC, upload to blog WordPress root via FTP/cPanel File Manager, click Verify immediately.",
            "status": "done",
            "testStrategy": "GSC shows green checkmark with 'Ownership verified' message. Property dashboard becomes accessible with data collection starting.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T17:01:05.761Z"
          },
          {
            "id": 3,
            "title": "Submit sitemap_index.xml to Google Search Console",
            "description": "Navigate to Sitemaps section in GSC and submit the Rank Math generated sitemap index file for the blog property.",
            "dependencies": [
              2
            ],
            "details": "In verified blog property, go to Sitemaps section (left sidebar). Enter 'sitemap_index.xml' in the 'Add a new sitemap' field. Click Submit button. GSC will fetch and process the sitemap, discovering post-sitemap.xml and page-sitemap.xml references.",
            "status": "done",
            "testStrategy": "Sitemap shows 'Success' status in GSC Sitemaps report. Check 'Discovered URLs' count matches expected blog posts/pages. Coverage report begins populating within 24-48 hours.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T17:03:06.924Z"
          },
          {
            "id": 4,
            "title": "Request indexing for priority blog posts via URL Inspection tool",
            "description": "Use GSC URL Inspection tool to manually request indexing for key blog posts to accelerate Google discovery and crawling.",
            "dependencies": [
              3
            ],
            "details": "In GSC, use URL Inspection tool (top search bar). Enter full URLs of 5-10 priority blog posts (newest or most important content). For each URL showing 'URL is not on Google', click 'Request Indexing' button. Google will prioritize crawling these URLs within days rather than weeks.",
            "status": "done",
            "testStrategy": "URL Inspection shows 'Indexing requested' confirmation message for each submitted URL. Monitor Index Coverage report over 3-7 days to see URLs move from 'Discovered' to 'Indexed' status.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T17:03:06.935Z"
          },
          {
            "id": 5,
            "title": "Verify GSC setup completion and monitor initial reports",
            "description": "Confirm all GSC configuration is complete and review initial data in Coverage, Sitemaps, and Performance reports to ensure proper setup.",
            "dependencies": [
              4
            ],
            "details": "Check GSC verification status remains active (green checkmark). Review Sitemaps report: sitemap_index.xml shows 'Success' with no errors. Check Coverage report for any errors or warnings. Verify Performance report begins collecting impression/click data within 2-3 days. Document any issues for resolution.",
            "status": "done",
            "testStrategy": "GSC dashboard shows: verified property, successfully processed sitemap with discovered URLs matching blog content count, no critical errors in Coverage report, Performance data begins appearing within 48-72 hours.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T17:03:06.942Z"
          }
        ],
        "complexity": 4,
        "recommendedSubtasks": 0,
        "expansionPrompt": "No expansion needed - standard GSC property verification and submission.",
        "updatedAt": "2026-02-10T17:03:06.942Z"
      },
      {
        "id": 21,
        "title": "Resolve React GSC Coverage Issues and Request Indexing",
        "description": "Address duplicate content, 404s, noindex issues in React site GSC.",
        "details": "Review Coverage report, fix canonical duplicates via SEO component, request indexing for key pages, set www preferred domain.",
        "testStrategy": "Monitor GSC for 48hrs post-fix, verify error count drops to zero, check indexed pages count increases.",
        "priority": "medium",
        "dependencies": [
          "18"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze GSC Coverage Report and Categorize Issues",
            "description": "Review Google Search Console Coverage report to identify and categorize all indexing issues including 404 errors, duplicate content, noindex pages, and canonical issues.",
            "dependencies": [],
            "details": "Access GSC Coverage report and export all errors and warnings. Create a spreadsheet categorizing issues by type: 404 errors (broken links), duplicate content (pages with similar/identical content), noindex tags (pages blocked from indexing), and canonical conflicts. Prioritize issues based on impact to key pages and traffic potential. Document URLs affected and root causes for each category.",
            "status": "done",
            "testStrategy": "Verify all issues are documented with categories, URLs, and root causes. Cross-reference with site structure to ensure no issues are missed.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T17:54:47.602Z"
          },
          {
            "id": 2,
            "title": "Fix Canonical Tags and Redirect Issues in React SEO Component",
            "description": "Implement fixes for canonical URL duplicates and redirect issues identified in the Coverage report by updating the React SEO component and routing configuration.",
            "dependencies": [
              1
            ],
            "details": "Update React SEO component to ensure proper canonical tags are set for all pages. Fix duplicate content issues by implementing correct canonical URLs pointing to preferred versions. Address redirect chains and 404 errors by updating routing configuration. Set www as preferred domain in both GSC and site configuration. Ensure all internal links use consistent URL format (www vs non-www).",
            "status": "done",
            "testStrategy": "Test canonical tags on sample pages using browser inspector and SEO tools. Verify redirects work correctly (301 status). Check that www preference is reflected across all pages.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T17:55:36.355Z"
          },
          {
            "id": 3,
            "title": "Request Bulk Indexing for Key Pages and Monitor Results",
            "description": "Submit indexing requests for priority pages through Google Search Console and monitor indexing status over 48-hour period to verify improvements.",
            "dependencies": [
              2
            ],
            "details": "Identify key pages for indexing priority (homepage, main service pages, high-value content). Use GSC URL Inspection tool to request indexing for each priority page. Submit sitemap if not already done. Monitor GSC Coverage report for 48 hours to track error count reduction and indexed pages count increase. Document before/after metrics including total indexed pages, error counts by category, and coverage percentage.",
            "status": "done",
            "testStrategy": "Monitor GSC for 48hrs post-fix, verify error count drops to zero or near-zero, check indexed pages count increases by at least 20%, confirm key pages appear in index via site: search.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T18:09:25.360Z"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 3,
        "expansionPrompt": "1) Analyze GSC Coverage report and categorize issues (404s, duplicates, noindex), 2) Fix canonical/redirect issues from prior SEO tasks, 3) Bulk request indexing for key pages and monitor results.",
        "updatedAt": "2026-02-10T18:09:25.360Z"
      },
      {
        "id": 22,
        "title": "Cross-Domain Linking and Canonical Verification",
        "description": "Verify canonicals correct, add internal links between main site and blog.",
        "details": "Audit all pages for correct canonical URLs, add blog links from ArticlesInsights.tsx/MesaNews.tsx, ensure blog posts link to services. Check no duplicate content.",
        "testStrategy": "Use Screaming Frog to crawl both sites, verify canonical chains, check internal link structure.",
        "priority": "medium",
        "dependencies": [
          "16",
          "20"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Audit canonical URLs across both domains using Screaming Frog",
            "description": "Perform comprehensive canonical URL audit across main React site and WordPress blog to identify incorrect canonicals, canonical chains, and duplicate content issues.",
            "dependencies": [],
            "details": "Use Screaming Frog SEO Spider to crawl both www.mesagroupconsulting.com and blog.mesagroupconsulting.com. Export canonical URL report and identify: 1) Pages with missing canonical tags, 2) Canonical chains (ABC), 3) Self-referencing canonicals, 4) Cross-domain canonical issues, 5) Duplicate content across domains. Document all findings in spreadsheet with URL, current canonical, recommended canonical, and priority level.",
            "status": "done",
            "testStrategy": "Verify Screaming Frog crawl completes successfully for both domains, validate exported reports contain canonical data, cross-reference findings with manual spot-checks of 10+ pages, ensure no canonical chains exist after fixes.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T19:02:19.971Z"
          },
          {
            "id": 2,
            "title": "Implement cross-domain internal links between React and WordPress sites",
            "description": "Add strategic internal links from main site components to blog posts and from WordPress blog posts back to React service pages, considering nofollow attributes where appropriate.",
            "dependencies": [
              1
            ],
            "details": "In React codebase: Update ArticlesInsights.tsx and MesaNews.tsx to include contextual links to relevant blog.mesagroupconsulting.com posts (use dofollow for editorial links). In WordPress: Edit blog posts to add internal links to www.mesagroupconsulting.com service pages with relevant anchor text. Create linking matrix mapping blog categories to service pages. Implement links as standard <a> tags with appropriate rel attributes. Ensure all links use HTTPS and absolute URLs for cross-domain references.",
            "status": "done",
            "testStrategy": "Click-test all implemented links to verify they resolve correctly, use Screaming Frog to crawl and verify internal link structure shows cross-domain connections, check that nofollow/dofollow attributes are correctly applied, validate no broken links exist using link checker tool.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T19:02:22.008Z"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 2,
        "expansionPrompt": "1) Audit canonical URLs across both domains using Screaming Frog, 2) Implement cross-domain links (ReactWP and WPReact) with nofollow considerations.",
        "updatedAt": "2026-02-10T19:02:22.008Z"
      },
      {
        "id": 23,
        "title": "Technical SEO Audits and LocalBusiness Schema Addition",
        "description": "Run Lighthouse audits, fix heading structure/images, add LocalBusiness structured data to React site footer.",
        "details": "Add to index.html or global layout: JSON-LD with NAP: {\"@type\":\"LocalBusiness\",\"name\":\"Mesa Group Consulting\",\"address\":{\"@type\":\"PostalAddress\",\"streetAddress\":\"5001 California Ave Suite 219\",\"addressLocality\":\"Bakersfield\",\"addressRegion\":\"CA\",\"postalCode\":\"93309\"},\"telephone\":\"(661) 310-3040\"}. Lighthouse target 90+ SEO.",
        "testStrategy": "Lighthouse reports both sites, Google's Rich Results Test for schema, verify Core Web Vitals passing.",
        "priority": "medium",
        "dependencies": [
          "21"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Run Lighthouse audits and fix heading structure/image issues",
            "description": "Execute Lighthouse audits on the React site to identify SEO, performance, and accessibility issues. Fix heading hierarchy problems and optimize images for better Core Web Vitals scores.",
            "dependencies": [],
            "details": "Run Lighthouse in Chrome DevTools for both desktop and mobile. Document current SEO score and identify issues. Fix heading structure to ensure proper h1-h6 hierarchy (only one h1 per page). Optimize images by adding alt text, implementing lazy loading, using appropriate formats (WebP), and compressing file sizes. Address any other critical SEO issues flagged by Lighthouse. Target: achieve 90+ SEO score.",
            "status": "done",
            "testStrategy": "Run Lighthouse audits before and after fixes. Verify SEO score reaches 90+, all images have alt text, heading structure passes accessibility checks, and Core Web Vitals metrics (LCP, FID, CLS) are in green range.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T18:20:06.281Z"
          },
          {
            "id": 2,
            "title": "Implement LocalBusiness JSON-LD schema in React site",
            "description": "Add LocalBusiness structured data markup with NAP (Name, Address, Phone) information to the React site footer or global layout for improved local SEO.",
            "dependencies": [
              1
            ],
            "details": "Add JSON-LD script tag to index.html or global layout component with LocalBusiness schema: {\"@context\":\"https://schema.org\",\"@type\":\"LocalBusiness\",\"name\":\"Mesa Group Consulting\",\"address\":{\"@type\":\"PostalAddress\",\"streetAddress\":\"5001 California Ave Suite 219\",\"addressLocality\":\"Bakersfield\",\"addressRegion\":\"CA\",\"postalCode\":\"93309\"},\"telephone\":\"(661) 310-3040\"}. Ensure proper JSON formatting and placement in the document head or footer component.",
            "status": "done",
            "testStrategy": "Validate schema implementation using Google's Rich Results Test and Schema Markup Validator. Verify JSON-LD appears in page source, is properly formatted, and passes validation without errors or warnings.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T18:20:17.506Z"
          },
          {
            "id": 3,
            "title": "Validate schema markup and verify Core Web Vitals compliance",
            "description": "Use Google's Rich Results Test to validate LocalBusiness schema implementation and confirm Core Web Vitals metrics meet performance standards.",
            "dependencies": [
              2
            ],
            "details": "Test the live site URL using Google's Rich Results Test tool to confirm LocalBusiness schema is recognized and eligible for rich results. Run PageSpeed Insights to verify Core Web Vitals (LCP < 2.5s, FID < 100ms, CLS < 0.1) pass thresholds. Check Google Search Console for any structured data errors. Document final Lighthouse SEO score and Core Web Vitals status.",
            "status": "done",
            "testStrategy": "Google Rich Results Test shows LocalBusiness schema with no errors. PageSpeed Insights shows all Core Web Vitals in green. Final Lighthouse audit confirms 90+ SEO score. Google Search Console shows no structured data errors after indexing.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T18:20:27.495Z"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 3,
        "expansionPrompt": "1) Lighthouse audits and heading/image fixes, 2) Implement LocalBusiness JSON-LD schema, 3) Validate schema with Google's Rich Results Test and Core Web Vitals.",
        "updatedAt": "2026-02-10T18:20:27.495Z"
      },
      {
        "id": 24,
        "title": "Optimize index.html Meta Tags and Analytics Integration",
        "description": "Update React index.html OG images/favicons, verify GA4 on both sites, link GSC to Analytics.",
        "details": "Set og:image to absolute https://www.mesagroupconsulting.com/og-image.jpg, add preconnect to Google fonts/CDN. Confirm GA4 tags fire via DebugView.",
        "testStrategy": "Test index.html direct access (JS disabled), GA4 real-time reports show traffic, GSC linked successfully.",
        "priority": "low",
        "dependencies": [
          "23"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Update index.html OG images/favicons/preconnect",
            "description": "Update React index.html with absolute OG image URLs, favicon references, and add preconnect tags for Google fonts and CDN resources.",
            "dependencies": [],
            "details": "Modify public/index.html to set og:image meta tag to absolute URL https://www.mesagroupconsulting.com/og-image.jpg. Update og:image:secure_url, twitter:image tags similarly. Verify favicon links are correct. Add <link rel='preconnect' href='https://fonts.googleapis.com'> and <link rel='preconnect' href='https://fonts.gstatic.com' crossorigin> for Google Fonts. Add preconnect for any CDN resources used. Ensure all meta tags follow Open Graph protocol standards.",
            "status": "done",
            "testStrategy": "Test index.html direct access with JavaScript disabled to verify meta tags render correctly. Use Facebook Sharing Debugger and Twitter Card Validator to confirm OG images load properly. Check browser DevTools Network tab to verify preconnect resources are loaded early. Validate HTML with W3C validator.",
            "parentId": "undefined",
            "updatedAt": "2026-02-10T18:23:30.992Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 1,
        "expansionPrompt": "Split into: 1) Update index.html OG images/favicons/preconnect, 2) Verify GA4 implementation and GSC-Analytics linking.",
        "updatedAt": "2026-02-10T18:23:30.992Z"
      },
      {
        "id": 25,
        "title": "WordPress Technical Audit and Content Optimization",
        "description": "Ensure all blog posts have green Rank Math scores, focus keywords, internal links to main site.",
        "details": "Bulk edit posts: add focus keywords (credit repair, business funding), unique metas, service links. Optimize images with W3 Total Cache.",
        "testStrategy": "Rank Math analysis shows 100% green scores, Lighthouse mobile 80+, verify Article schema.",
        "priority": "medium",
        "dependencies": [
          "20"
        ],
        "status": "deferred",
        "subtasks": [
          {
            "id": 1,
            "title": "Bulk optimize existing blog posts with focus keywords, meta descriptions, and internal links",
            "description": "Edit all existing WordPress blog posts to add focus keywords (credit repair, business funding), write unique meta descriptions, and insert internal links to main site services.",
            "dependencies": [],
            "details": "Access WordPress admin and bulk edit all blog posts. For each post: assign relevant focus keywords from the list (credit repair, business funding, etc.), write unique meta descriptions optimized for SEO, add 2-3 internal links to main site service pages (mesagroupconsulting.com), ensure proper heading structure. Use Rank Math's content analysis to achieve green scores for each post. Focus on improving SEO metrics like keyword density, readability, and link structure.",
            "status": "pending",
            "testStrategy": "Verify Rank Math analysis shows 100% green scores across all posts. Check that each post has unique meta description, at least one focus keyword, and 2-3 internal links. Validate that internal links point to correct service pages on main site.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Configure W3 Total Cache for image optimization and validate Rank Math scores",
            "description": "Set up W3 Total Cache plugin for image optimization, enable lazy loading, and perform final validation of all Rank Math scores and schema markup.",
            "dependencies": [
              1
            ],
            "details": "Install/configure W3 Total Cache plugin in WordPress admin. Enable image optimization settings: lazy loading, WebP conversion if supported, browser caching for images. Configure CDN settings if applicable. After optimization, run final Rank Math validation across all posts to ensure green scores maintained. Test Lighthouse mobile performance (target 80+). Verify Article schema is properly implemented and validate using Google's Rich Results Test.",
            "status": "pending",
            "testStrategy": "Run Lighthouse audit targeting mobile score 80+. Verify W3 Total Cache is active and images are lazy-loaded. Use Google Rich Results Test to confirm Article schema validation. Check Rank Math dashboard shows 100% green scores. Test page load times before/after caching implementation.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 2,
        "expansionPrompt": "1) Bulk optimize existing posts (focus keywords, metas, internal links), 2) Configure image optimization (W3 Total Cache) and validate Rank Math scores.",
        "updatedAt": "2026-02-10T19:20:59.476Z"
      },
      {
        "id": 26,
        "title": "Establish SEO Monitoring and Baseline Documentation",
        "description": "Set up GSC alerts, document baseline metrics, create review checklist.",
        "details": "GSC > Settings > Alerts, record current indexed pages/traffic/errors. Create Google Sheet with weekly checklist: GSC errors, rankings, Lighthouse scores.",
        "testStrategy": "Verify alert emails received for test issues, baseline metrics match GSC/Analytics data.",
        "priority": "low",
        "dependencies": [
          "21",
          "23",
          "24"
        ],
        "status": "deferred",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure GSC alerts and record baseline metrics",
            "description": "Set up Google Search Console alerts for critical SEO issues and document current baseline metrics including indexed pages, traffic, and errors.",
            "dependencies": [
              21,
              23,
              24
            ],
            "details": "Navigate to GSC > Settings > Alerts and configure notifications for coverage errors, indexing issues, and manual actions. Document baseline metrics: current indexed pages count, average traffic (impressions/clicks), existing errors from Coverage report, and mobile usability issues. Record all metrics in a structured format with timestamp for future comparison.",
            "status": "pending",
            "testStrategy": "Verify alert emails are received by triggering a test issue (e.g., temporarily blocking a page). Confirm baseline metrics match current GSC and Analytics data by cross-referencing reports.",
            "parentId": "undefined"
          }
        ],
        "complexity": 4,
        "recommendedSubtasks": 1,
        "expansionPrompt": "Split into: 1) Configure GSC alerts and record baseline metrics, 2) Create monitoring Google Sheet with weekly checklist template.",
        "updatedAt": "2026-02-10T19:20:59.490Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-02-10T19:20:59.490Z",
      "taskCount": 16,
      "completedCount": 14,
      "tags": [
        "master"
      ],
      "created": "2026-02-12T00:45:24.994Z",
      "description": "Tasks for master context",
      "updated": "2026-02-12T00:45:24.994Z"
    }
  },
  "feature-content-generator": {
    "tasks": [
      {
        "id": "11",
        "title": "Project Setup and Build Infrastructure",
        "description": "Initialize Vite project with React, TypeScript, and Tailwind CSS. Establish project structure, copy reusable components from Nano Banana, configure environment variables, and prepare development environment.",
        "details": "Clone Nano Banana Vite/React structure to establish foundation. Copy vite.config.ts, tailwind.config.js, postcss.config.js, tsconfig.json (approximately 60% code reuse). Install dependencies: React 18, TypeScript 5.6+, Tailwind CSS 3.4+, lucide-react 0.454+, Socket.io-client 4.7+, axios 1.6+, jszip 3.10+, file-saver 2.0+. Create .env files for VITE_API_URL (default: http://localhost:8000) and VITE_WS_URL (default: ws://localhost:8000). Set up proper TypeScript configuration with strict mode enabled. Configure Tailwind with Mesa Group color palette already included from Nano Banana. Set up Git pre-commit hooks to ensure code quality. Use Vite's development server on port 5173 with hot module replacement. Document all environment setup steps for reproducibility.",
        "testStrategy": "Verify npm install completes without errors. Run `npm run dev` and confirm Vite development server starts on port 5173. Check that Tailwind CSS loads with Mesa colors available. Verify TypeScript compilation has no errors. Confirm all environment variables are accessible via import.meta.env. Test HMR by modifying a component and verifying live reload works.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initial Vite Project Scaffolding and Dependency Installation",
            "description": "Create new Vite project with React and TypeScript template, install all required dependencies including React 18, TypeScript 5.6+, Tailwind CSS 3.4+, lucide-react, Socket.io-client, axios, jszip, and file-saver.",
            "dependencies": [],
            "details": "Run `npm create vite@latest` with React-TypeScript template. Install core dependencies: react@18, react-dom@18, typescript@5.6+, vite@latest. Install UI dependencies: tailwindcss@3.4+, postcss, autoprefixer, lucide-react@0.454+. Install networking: socket.io-client@4.7+, axios@1.6+. Install file handling: jszip@3.10+, file-saver@2.0+. Install dev dependencies: @types/node, @types/react, @types/react-dom. Run npm install and verify no errors. Create basic src folder structure with components, types, services, utils, and hooks directories.",
            "status": "pending",
            "testStrategy": "Verify npm install completes without errors or warnings. Check package.json contains all specified dependencies with correct version ranges. Run `npm list` to confirm dependency tree resolves correctly. Verify node_modules folder is populated and src folder structure exists.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Configuration File Migration from Nano Banana",
            "description": "Copy and adapt vite.config.ts, tailwind.config.js, postcss.config.js, and tsconfig.json from Nano Banana project with Mesa Group color palette and strict TypeScript settings.",
            "dependencies": [
              1
            ],
            "details": "Copy vite.config.ts from Nano Banana and configure for port 5173 with HMR enabled. Copy tailwind.config.js including Mesa Group color palette (Mesa yellow, brand colors). Copy postcss.config.js with tailwindcss and autoprefixer plugins. Copy tsconfig.json with strict mode enabled, target ES2020+, module ESNext, jsx react-jsx, and proper path aliases (@/ for src). Ensure all config files are compatible with installed dependency versions. Initialize Tailwind by running `npx tailwindcss init -p` if needed and merge Nano Banana configurations.",
            "status": "pending",
            "testStrategy": "Run `tsc --noEmit` to verify TypeScript configuration compiles without errors. Run `npm run dev` and confirm Vite starts on port 5173. Check browser console for Tailwind CSS loading. Create test component using Mesa color classes (bg-mesa-yellow) and verify colors render correctly. Verify HMR works by making a change and seeing instant update.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Environment Variable Setup and Validation",
            "description": "Create .env and .env.example files with VITE_API_URL and VITE_WS_URL variables, implement environment variable validation, and document configuration options.",
            "dependencies": [
              2
            ],
            "details": "Create .env file with VITE_API_URL=http://localhost:8000 and VITE_WS_URL=ws://localhost:8000. Create .env.example with same structure but placeholder values for documentation. Add .env to .gitignore to prevent committing secrets. Create src/config/env.ts utility to validate and export environment variables using import.meta.env with TypeScript type safety. Add runtime validation to ensure required variables are present. Document all environment variables in README.md with descriptions, default values, and usage examples.",
            "status": "pending",
            "testStrategy": "Verify .env file exists and is in .gitignore. Run `npm run dev` and check that environment variables are accessible via import.meta.env.VITE_API_URL and import.meta.env.VITE_WS_URL. Test validation by temporarily removing a required variable and confirming error is thrown. Create test component that displays env values and verify correct URLs appear. Check .env.example is committed to git while .env is ignored.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Git Hooks and Code Quality Tooling Setup",
            "description": "Configure Git repository with pre-commit hooks using husky, set up ESLint and Prettier for code quality, and establish linting rules for TypeScript and React.",
            "dependencies": [
              2
            ],
            "details": "Initialize Git repository with `git init` if not already done. Install husky for Git hooks and lint-staged for pre-commit file checking. Install ESLint with TypeScript and React plugins (@typescript-eslint/parser, @typescript-eslint/eslint-plugin, eslint-plugin-react, eslint-plugin-react-hooks). Install Prettier and eslint-config-prettier to avoid conflicts. Create .eslintrc.json with strict rules for TypeScript and React best practices. Create .prettierrc with formatting rules (semi, singleQuote, tabWidth). Set up pre-commit hook to run `lint-staged` which executes ESLint and Prettier on staged files. Add npm scripts: lint, lint:fix, format.",
            "status": "pending",
            "testStrategy": "Make a test commit with intentionally poorly formatted code and verify pre-commit hook blocks it. Run `npm run lint` and confirm it checks all TypeScript files. Run `npm run format` and verify Prettier formats files correctly. Fix linting errors and confirm commit succeeds. Test hook by staging files with TypeScript errors and verifying commit is prevented with clear error messages.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Development Server Verification and Documentation",
            "description": "Verify complete development environment setup, test all configurations work together, and create comprehensive setup documentation for team reproducibility.",
            "dependencies": [
              3,
              4
            ],
            "details": "Create comprehensive README.md documenting: prerequisites (Node.js version), installation steps, environment variable configuration, available npm scripts (dev, build, preview, lint, format), project structure overview, and troubleshooting guide. Test complete setup flow: run `npm install`, `npm run dev`, verify server starts on port 5173, check HMR works, verify Tailwind styles load, confirm TypeScript compiles, test environment variables are accessible. Create a simple test page (App.tsx) that displays Mesa colors, uses lucide-react icons, and shows environment variables to verify all integrations. Document any platform-specific setup requirements (Windows/Mac/Linux). Add CONTRIBUTING.md with development workflow guidelines.",
            "status": "pending",
            "testStrategy": "Follow README.md setup instructions on a fresh clone to verify reproducibility. Run `npm run dev` and access http://localhost:5173 to confirm server responds. Verify test page displays Mesa colors correctly and lucide-react icons render. Check TypeScript compilation with `tsc --noEmit` shows no errors. Test HMR by editing a component and confirming instant browser update. Verify all npm scripts (dev, build, lint, format) execute successfully. Have another team member follow documentation to validate clarity.",
            "parentId": "undefined"
          }
        ],
        "complexity": 4,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Break down the project setup into: 1) Initial Vite project scaffolding and dependency installation, 2) Configuration file migration from Nano Banana (vite.config.ts, tailwind.config.js, postcss.config.js, tsconfig.json), 3) Environment variable setup and validation (.env files with VITE_API_URL and VITE_WS_URL), 4) Git hooks and code quality tooling setup, 5) Development server verification and documentation. Each subtask should include specific verification steps and success criteria.",
        "updatedAt": "2026-02-12T20:24:36.459Z"
      },
      {
        "id": "12",
        "title": "Core Component Architecture and Type Definitions",
        "description": "Establish component folder structure, define TypeScript interfaces for all data types, create custom hooks (useGeneration, useWebSocket), and implement base component architecture with proper state management.",
        "details": "Create src/components folder with subdirectories for page-level components (InputForm, ProgressDisplay, OutputDisplay) and UI components (ProgressStep, DownloadButton, ErrorDisplay, Header). Create src/types with interfaces: Generation (input, inputType, qualityScore, duration), ProgressEvent (type, stepId, data), ContentPackage (blogPost, youtubeScript, metadata), and ErrorState. Create src/services for websocketService.ts, apiClient.ts, downloadService.ts, and storageService.ts. Create src/hooks with useGeneration.ts (manages generation workflow state using useState) and useWebSocket.ts (custom hook for WebSocket connection management with auto-reconnect logic). Implement src/utils with inputDetection.ts (auto-detection logic for 4 input types) and formatters.ts. Use React Context or Zustand for shared state management following 2025 best practices (prefer Context for simple cases, Zustand for complex state). Ensure all components accept proper TypeScript props interfaces. Create a centralApp.tsx that orchestrates the main workflow.",
        "testStrategy": "Verify all TypeScript files compile without errors using `tsc --noEmit`. Create unit tests for inputDetection utility function covering YouTube URLs, Answer the Public questions, topics, and competitor URLs with 95%+ accuracy. Test type safety by intentionally passing wrong prop types and verifying TypeScript catches errors. Verify custom hooks use proper dependency arrays to prevent infinite loops. Test localStorage operations in storageService with sample data.",
        "priority": "high",
        "dependencies": [
          "11"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create folder structure and scaffold component files",
            "description": "Establish the complete project folder structure with all necessary directories and create empty scaffold files for components, types, services, hooks, and utilities.",
            "dependencies": [],
            "details": "Create src/components folder with subdirectories: src/components/pages (InputForm.tsx, ProgressDisplay.tsx, OutputDisplay.tsx) and src/components/ui (ProgressStep.tsx, DownloadButton.tsx, ErrorDisplay.tsx, Header.tsx). Create src/types/index.ts for type definitions. Create src/services directory with websocketService.ts, apiClient.ts, downloadService.ts, storageService.ts. Create src/hooks directory with useGeneration.ts and useWebSocket.ts. Create src/utils directory with inputDetection.ts and formatters.ts. Create src/App.tsx as the main orchestrator. All files should be created with basic TypeScript boilerplate and export statements to ensure proper module structure.",
            "status": "pending",
            "testStrategy": "Verify all directories exist using file system checks. Confirm all .ts and .tsx files are created and contain valid TypeScript syntax. Run `tsc --noEmit` to ensure no compilation errors. Check that all files have proper export statements and can be imported without errors.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Define TypeScript interfaces and type definitions",
            "description": "Create comprehensive TypeScript interfaces for all data types including Generation, ProgressEvent, ContentPackage, ErrorState, and component prop types with complete type safety.",
            "dependencies": [
              1
            ],
            "details": "In src/types/index.ts, define: Generation interface with fields (input: string, inputType: 'youtube' | 'atp' | 'topic' | 'competitor', qualityScore: number, duration: number, timestamp: Date). ProgressEvent interface with fields (type: 'step_start' | 'step_complete' | 'step_error', stepId: string, data: any, timestamp: Date). ContentPackage interface with fields (blogPost: { title: string, content: string, wordCount: number }, youtubeScript: { title: string, script: string, duration: number }, metadata: { keywords: string[], generatedAt: Date }). ErrorState interface with fields (message: string, code?: string, timestamp: Date, recoverable: boolean). Define prop interfaces for all components ensuring strict typing. Use TypeScript utility types (Partial, Pick, Omit) where appropriate for flexibility.",
            "status": "pending",
            "testStrategy": "Verify TypeScript compilation with `tsc --noEmit` passes without errors. Create test files that intentionally use wrong types and confirm TypeScript catches the errors. Test that all interfaces can be imported and used in component files. Validate that discriminated unions work correctly for inputType and ProgressEvent type fields.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement service layer (WebSocket, API, download, storage)",
            "description": "Build service layer modules for WebSocket communication, API client, file download functionality, and localStorage management with proper error handling and TypeScript typing.",
            "dependencies": [
              2
            ],
            "details": "Implement websocketService.ts with Socket.io-client integration, connection management, event listeners, auto-reconnect logic (exponential backoff), and typed event emitters/listeners. Implement apiClient.ts using axios with base URL from environment variables, request/response interceptors, error handling, and typed API methods for generation endpoints. Implement downloadService.ts using jszip and file-saver to create ZIP packages containing blog posts and YouTube scripts with proper MIME types. Implement storageService.ts with methods for saving/loading generation history, input persistence, and user preferences using localStorage with JSON serialization and error handling for quota exceeded scenarios. All services should export singleton instances or factory functions with proper TypeScript types.",
            "status": "pending",
            "testStrategy": "Unit test websocketService connection, disconnection, and reconnection logic with mock Socket.io. Test apiClient with mock axios responses for success and error scenarios. Test downloadService by generating a test ZIP file and verifying contents. Test storageService with localStorage mock, including quota exceeded scenarios. Verify all services handle errors gracefully and return typed responses.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Develop custom hooks (useGeneration and useWebSocket)",
            "description": "Create useGeneration hook for managing generation workflow state and useWebSocket hook for WebSocket connection management with auto-reconnect logic and proper dependency management.",
            "dependencies": [
              3
            ],
            "details": "Implement useGeneration.ts hook using useState and useEffect to manage: generation state (idle, processing, complete, error), current step tracking, progress events array, input data, quality score, and duration. Include methods: startGeneration(input), cancelGeneration(), resetState(). Integrate with apiClient and websocketService. Implement useWebSocket.ts hook with: connection state management, auto-reconnect with exponential backoff (max 5 retries), event subscription/unsubscription, typed event handlers, and cleanup on unmount. Use useRef to prevent infinite loops in useEffect dependencies. Both hooks should return properly typed objects with state and methods. Implement proper error boundaries and state transitions.",
            "status": "pending",
            "testStrategy": "Test useGeneration hook with React Testing Library: verify state transitions from idle  processing  complete, test error handling, verify cleanup on unmount. Test useWebSocket hook: mock Socket.io connection, verify auto-reconnect triggers after disconnect, test event subscription/unsubscription, verify no memory leaks or infinite loops. Use act() wrapper for state updates and verify all dependencies are properly declared in useEffect arrays.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Build utility functions (input detection and formatters)",
            "description": "Implement inputDetection utility for auto-detecting input types with 95%+ accuracy and formatters utility for data transformation and display formatting.",
            "dependencies": [
              2
            ],
            "details": "Implement inputDetection.ts with detectInputType(input: string) function returning 'youtube' | 'atp' | 'competitor' | 'topic'. Use regex patterns: YouTube (youtube\\.com\\/watch\\?v=|youtu\\.be\\/), ATP questions (answerthepublic\\.com or question patterns with who/what/when/where/why/how), competitor URLs (http(s)?:\\/\\/ pattern), default to 'topic'. Include confidence scoring and edge case handling. Implement formatters.ts with functions: formatDuration(seconds: number), formatTimestamp(date: Date), formatQualityScore(score: number), truncateText(text: string, maxLength: number), formatFileSize(bytes: number). All functions should be pure, well-typed, and handle edge cases (null, undefined, invalid inputs).",
            "status": "pending",
            "testStrategy": "Create comprehensive unit tests for inputDetection covering: YouTube URLs (youtube.com/watch?v=abc123, youtu.be/abc123, with query params), ATP questions (various question formats), competitor URLs (http/https, with/without www), plain topics. Verify 95%+ accuracy across 50+ test cases. Test formatters with edge cases: zero values, negative numbers, very large numbers, null/undefined inputs. Verify all functions are pure (same input = same output).",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Implement state management architecture and App orchestration",
            "description": "Make architectural decision between React Context and Zustand for state management, implement chosen solution following 2025 best practices, and create App.tsx to orchestrate the main workflow.",
            "dependencies": [
              4,
              5
            ],
            "details": "Evaluate Context vs Zustand: use React Context for simple shared state (theme, user preferences, current generation), use Zustand if state complexity grows (multiple generations, undo/redo, complex derived state). Implement chosen solution: if Context, create GenerationContext with provider wrapping App, include state and dispatch methods; if Zustand, create store with slices for generation, UI state, and history. Implement App.tsx to orchestrate workflow: integrate useGeneration and useWebSocket hooks, manage routing between InputForm  ProgressDisplay  OutputDisplay, handle global error boundaries, implement state persistence on page refresh, and coordinate component communication. Ensure proper TypeScript typing throughout with strict mode enabled. Follow React 18 best practices with concurrent features support.",
            "status": "pending",
            "testStrategy": "Test state management: verify state updates propagate to all consuming components, test performance with React DevTools Profiler (no unnecessary re-renders), verify state persistence across page refreshes. Test App.tsx orchestration: verify workflow transitions (input  progress  output), test error boundary catches and displays errors, verify WebSocket connection establishes on mount and cleans up on unmount. Integration test: complete end-to-end flow from input submission to output display with mocked backend responses.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Divide the architecture work into: 1) Folder structure creation and component scaffolding (src/components, src/types, src/services, src/hooks, src/utils), 2) TypeScript interface definitions (Generation, ProgressEvent, ContentPackage, ErrorState with complete type safety), 3) Service layer implementation (websocketService.ts, apiClient.ts, downloadService.ts, storageService.ts), 4) Custom hooks development (useGeneration.ts with state management, useWebSocket.ts with connection logic), 5) Utility functions (inputDetection.ts, formatters.ts), 6) State management architecture decision and implementation (Context vs Zustand). Each subtask should define clear interfaces and contracts.",
        "updatedAt": "2026-02-12T20:45:39.287Z"
      },
      {
        "id": "13",
        "title": "Input Form with Auto-Detection and Validation",
        "description": "Build InputForm component with large textarea, real-time auto-detection badge, localStorage persistence, and input validation. Implement debounced auto-detection logic to identify YouTube URLs, ATP questions, topics, or competitor URLs.",
        "details": "Create InputForm.tsx component with textarea (min 3 rows, auto-expanding using libraries like react-textarea-autosize or custom CSS). Implement debounced auto-detection using lodash.debounce or custom hook (300ms delay as specified). Create detection logic in utils/inputDetection.ts using regex patterns: YouTube URLs (youtube.com/watch?v=, youtu.be/), ATP questions (answerthepublic.com patterns or text-based heuristics), URLs (http/https), topics (general text). Display auto-detection badge with lucide-react icons (Video, HelpCircle, FileText, ExternalLink) that update smoothly. Add character counter showing current/minimum required (10 chars minimum). Disable Generate button when input < 10 characters. Implement localStorage persistence using storageService - save input on every keystroke, load on component mount. Add placeholder with examples: 'Paste YouTube URL, Answer the Public question, topic, or competitor article URL... Examples: how to fix bad credit | https://youtube.com/watch?v=ABC | debt relief strategies'. Trim whitespace automatically on paste detection. Apply Mesa Group styling with yellow accent on focus.",
        "testStrategy": "Test auto-detection accuracy with sample inputs: verify YouTube URL detection (both long and short forms), ATP question detection, plain topics, and competitor URLs all register > 95% accuracy. Test localStorage persistence by entering text, refreshing page, confirming text remains. Test debounce behavior with rapid typing - only final state after 300ms inactivity triggers badge update. Test character counter shows correctly. Verify Generate button is disabled below 10 characters, enabled above. Test on desktop and tablet viewports to ensure textarea is usable on both.",
        "priority": "high",
        "dependencies": [
          "12"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Basic Textarea Component with Auto-Expanding Behavior and Character Counter",
            "description": "Create the foundational InputForm.tsx component with a textarea that auto-expands based on content and displays a real-time character counter with minimum validation.",
            "dependencies": [],
            "details": "Implement InputForm.tsx with textarea using react-textarea-autosize library or custom CSS (min-height: 3 rows, max-height: 20 rows). Add character counter displaying current/minimum (10 chars minimum) positioned bottom-right of textarea. Apply Mesa Group styling with yellow accent (#F59E0B) on focus state. Add placeholder text: 'Paste YouTube URL, Answer the Public question, topic, or competitor article URL... Examples: how to fix bad credit | https://youtube.com/watch?v=ABC | debt relief strategies'. Implement automatic whitespace trimming on paste events. Create responsive layout that works on mobile and desktop.",
            "status": "pending",
            "testStrategy": "Test textarea auto-expansion by entering multiple lines of text (verify expands smoothly up to max height). Test character counter updates in real-time as user types. Verify placeholder displays correctly and disappears on focus. Test paste event whitespace trimming with various inputs. Verify Mesa Group yellow accent appears on focus. Test responsive behavior on mobile viewport.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Debounced Auto-Detection Logic with Regex Patterns for 4 Input Types",
            "description": "Implement debounced auto-detection system in utils/inputDetection.ts with regex patterns to identify YouTube URLs, ATP questions, competitor URLs, and topics with >95% accuracy.",
            "dependencies": [
              1
            ],
            "details": "Create utils/inputDetection.ts with detectInputType function using 300ms debounce (lodash.debounce or custom hook). Implement regex patterns: YouTube URLs (youtube.com/watch?v=, youtu.be/, youtube.com/embed/), ATP questions (answerthepublic.com URLs or text patterns like 'how to', 'what is', 'why does', 'can you'), competitor URLs (http://, https:// patterns excluding YouTube), topics (fallback for general text). Return InputType enum: 'youtube' | 'atp_question' | 'url' | 'topic'. Prioritize detection order: YouTube first, then ATP, then URLs, finally topics. Export TypeScript types for InputType and DetectionResult with confidence scores.",
            "status": "pending",
            "testStrategy": "Test with 50+ sample inputs across all 4 types to achieve >95% accuracy. Verify YouTube detection: 'https://youtube.com/watch?v=ABC123', 'https://youtu.be/XYZ789', 'youtube.com/embed/TEST'. Test ATP questions: 'how to fix bad credit', 'what is debt consolidation', answerthepublic.com URLs. Test competitor URLs: 'https://example.com/article', 'http://blog.site.com/post'. Test topics: 'debt relief strategies', 'credit repair tips'. Verify debounce delays detection by 300ms. Measure detection accuracy rate.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Dynamic Badge Display System with Lucide-React Icons and Smooth Transitions",
            "description": "Create dynamic badge component that displays detected input type with appropriate lucide-react icons and smooth CSS transitions based on auto-detection results.",
            "dependencies": [
              2
            ],
            "details": "Create DetectionBadge sub-component that receives InputType and displays corresponding lucide-react icon: Video (YouTube), HelpCircle (ATP questions), ExternalLink (URLs), FileText (topics). Implement smooth fade-in/fade-out transitions (200ms duration) when detection type changes. Position badge above or beside textarea with Mesa Group styling (yellow background for active detection, gray for no detection). Add tooltip showing detected type on hover. Use CSS transitions for opacity and transform properties. Ensure badge updates reactively when detectInputType result changes. Apply accessible ARIA labels for screen readers.",
            "status": "pending",
            "testStrategy": "Test badge appearance and icon changes by typing different input types sequentially. Verify smooth transitions occur within 200ms when switching between types. Test all 4 icon types display correctly: Video, HelpCircle, ExternalLink, FileText. Verify tooltip shows on hover with correct detection type. Test badge positioning on mobile and desktop. Verify ARIA labels are present for accessibility. Test rapid input changes to ensure transitions don't stack or glitch.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "LocalStorage Persistence Layer with Save-on-Keystroke and Load-on-Mount",
            "description": "Implement localStorage persistence using storageService to automatically save input on every keystroke and restore it when component mounts, ensuring user data is never lost.",
            "dependencies": [
              1
            ],
            "details": "Create or extend src/services/storageService.ts with saveInput and loadInput functions using localStorage API. Implement save-on-keystroke by calling saveInput in textarea onChange handler (after debounce to avoid excessive writes, 500ms delay). Store input value with key 'inputForm_content' and timestamp. Implement load-on-mount in useEffect hook to retrieve saved input and populate textarea. Add error handling for localStorage quota exceeded and browser privacy modes. Implement clearInput function for manual clearing. Add optional TTL (time-to-live) of 7 days to auto-expire old saved inputs. Handle edge cases: localStorage disabled, quota exceeded, corrupted data.",
            "status": "pending",
            "testStrategy": "Test save functionality by typing text, checking localStorage contains correct value with key 'inputForm_content'. Test load functionality by refreshing page and verifying text persists. Test with large inputs (>10KB) to verify quota handling. Test in private/incognito mode where localStorage may be disabled. Test TTL by mocking old timestamp and verifying expired data is cleared. Test clearInput function removes data from localStorage. Verify debounced saves don't cause performance issues with rapid typing.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Validation Logic and Generate Button State Management with Mesa Group Styling",
            "description": "Implement input validation rules, Generate button state management that disables when validation fails, and apply Mesa Group styling throughout the form component.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Create validation logic: minimum 10 characters required, maximum 5000 characters, non-empty after trim. Implement Generate button component with disabled state when input < 10 chars or validation fails. Add visual feedback: button grayed out when disabled, Mesa Group yellow (#F59E0B) background when enabled, hover effects with darker yellow. Display validation error messages below textarea when validation fails (red text, small font). Connect Generate button to parent component's onGenerate handler passing validated input and detected type. Apply consistent Mesa Group styling: yellow accents, proper spacing, typography (font-family from design system). Add loading state to button during generation. Implement keyboard shortcut (Ctrl/Cmd+Enter) to trigger generation when valid.",
            "status": "pending",
            "testStrategy": "Test Generate button disabled state with input < 10 characters. Test button enables exactly when input reaches 10 characters. Test maximum character limit validation (5000 chars). Verify validation error messages display correctly below textarea. Test button click triggers onGenerate with correct parameters (input text and detected type). Test keyboard shortcut Ctrl+Enter and Cmd+Enter trigger generation. Verify Mesa Group styling matches design system (yellow #F59E0B). Test loading state displays during generation. Test button remains disabled during active generation.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Break down the input form into: 1) Basic textarea component with auto-expanding behavior and character counter, 2) Debounced auto-detection logic implementation with regex patterns for 4 input types (YouTube URLs, ATP questions, URLs, topics), 3) Dynamic badge display system with lucide-react icons and smooth transitions, 4) localStorage persistence layer with save-on-keystroke and load-on-mount, 5) Validation logic and Generate button state management with Mesa Group styling. Each subtask should achieve >95% detection accuracy for its input type.",
        "updatedAt": "2026-02-12T20:48:44.101Z"
      },
      {
        "id": "14",
        "title": "WebSocket Integration and Progress State Management",
        "description": "Implement WebSocket connection management with auto-reconnect logic, progress state handling, and resilient connection recovery. Create websocketService and useWebSocket hook following current best practices from Socket.io v4.7+ documentation.",
        "details": "Create websocketService.ts using Socket.io-client 4.7+. Implement connection with auto-reconnect using exponential backoff (initial delay 1000ms, max delay 30000ms, multiplier 1.5, jitter enabled - following Socket.io best practices from [7]). Handle connection states: connecting, connected, disconnecting, disconnected. Implement 3 retry attempts before fallback to polling. Create event handlers for: connection_established, generation_started, step_start, step_progress, step_complete, generation_complete, error. Store connection state in custom hook useWebSocket.ts with proper cleanup in useEffect return. Implement progress state management using useState to track all 7 steps with their sub-items. Use useCallback to prevent unnecessary re-renders of step components. Handle disconnection gracefully with user-facing notification. Implement fallback to HTTP polling if WebSocket fails (poll /api/generation-status every 1 second). Store progress state in sessionStorage to preserve if page refreshes mid-generation. Emit events include proper JSON structure with step_id, details, timestamps.",
        "testStrategy": "Test WebSocket connection establishes on Generate click. Simulate connection drops and verify auto-reconnect triggers up to 3 times. Verify fallback to polling occurs after max retries. Send mock WebSocket events and verify progress state updates correctly. Test that progress persists across page refresh using sessionStorage. Verify no connection memory leaks using browser dev tools. Test on unreliable network using Chrome DevTools throttling. Verify latency < 500ms for progress updates.",
        "priority": "high",
        "dependencies": [
          "12",
          "13"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Socket.io-client Setup with Connection Configuration",
            "description": "Set up Socket.io-client 4.7+ with connection configuration, environment variables, and connection state management infrastructure.",
            "dependencies": [],
            "details": "Create websocketService.ts file and install socket.io-client@^4.7.0. Configure Socket.io connection with environment variables (VITE_WS_URL or fallback to window.location.origin). Set up connection options including transports: ['websocket', 'polling'], upgrade: true, rememberUpgrade: true. Define connection state enum/type for connecting, connected, disconnecting, disconnected states. Initialize socket instance with proper TypeScript types. Implement connection initialization function that accepts optional configuration overrides. Set up basic connection event listeners for 'connect', 'disconnect', 'connect_error'. Export socket instance and connection utilities for use in custom hook.",
            "status": "pending",
            "testStrategy": "Verify Socket.io-client initializes with correct version. Test connection establishes to backend WebSocket endpoint. Verify environment variable VITE_WS_URL is read correctly. Test connection state transitions through all 4 states. Verify TypeScript types are properly defined with no compilation errors.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Auto-Reconnect Logic with Exponential Backoff and Jitter",
            "description": "Implement exponential backoff reconnection strategy with 1s initial delay, 30s max delay, 1.5x multiplier, jitter enabled, and 3 retry attempts before fallback.",
            "dependencies": [
              1
            ],
            "details": "Implement exponential backoff algorithm in websocketService.ts with initial delay 1000ms, max delay 30000ms, multiplier 1.5. Add jitter calculation (random factor 0.5-1.5 of delay) to prevent thundering herd. Track retry attempt counter (max 3 attempts). Implement reconnection logic on 'disconnect' and 'connect_error' events. Calculate next delay: Math.min(initialDelay * Math.pow(multiplier, attempt) * jitter, maxDelay). Use setTimeout for delayed reconnection attempts. Reset retry counter on successful connection. Emit custom event 'max_retries_exceeded' after 3 failed attempts to trigger polling fallback. Log reconnection attempts with timestamps and delay values for debugging. Handle edge cases: manual disconnection should not trigger auto-reconnect, network changes should reset retry counter.",
            "status": "pending",
            "testStrategy": "Simulate connection drops and verify reconnection attempts occur with correct delays (1s, 1.5s, 2.25s approximately with jitter). Test that jitter adds randomness to delays. Verify max 3 retry attempts before emitting max_retries_exceeded event. Test that successful reconnection resets retry counter. Verify manual disconnect does not trigger auto-reconnect.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Event Handler Implementation for 7 WebSocket Event Types",
            "description": "Create event handlers for all 7 WebSocket events: connection_established, generation_started, step_start, step_progress, step_complete, generation_complete, and error with proper payload validation.",
            "dependencies": [
              1
            ],
            "details": "Implement event handler registration system in websocketService.ts for 7 event types. Define TypeScript interfaces for each event payload: ConnectionEstablished (timestamp, sessionId), GenerationStarted (generationId, inputType, timestamp), StepStart (step_id 1-7, stepName, timestamp), StepProgress (step_id, progress 0-100, details, subItems array, timestamp), StepComplete (step_id, stepName, duration, timestamp), GenerationComplete (generationId, qualityScore, files array, totalDuration, timestamp), Error (errorType, message, recoverable boolean, timestamp). Create event listener registration functions: onConnectionEstablished, onGenerationStarted, onStepStart, onStepProgress, onStepComplete, onGenerationComplete, onError. Implement event emitter pattern with callback arrays for each event type. Add payload validation using Zod or manual validation. Handle malformed events gracefully with error logging. Implement removeListener functions for cleanup. Store event callbacks in Map structure for efficient lookup.",
            "status": "pending",
            "testStrategy": "Send mock events for all 7 types and verify handlers are triggered with correct payloads. Test payload validation rejects malformed events. Verify multiple listeners can be registered for same event. Test removeListener properly unregisters callbacks. Verify event handlers receive proper TypeScript types with no compilation errors.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "useWebSocket Custom Hook with State Management and Cleanup",
            "description": "Create useWebSocket.ts custom React hook managing connection state, event subscriptions, progress tracking for 7 steps, and proper cleanup in useEffect.",
            "dependencies": [
              2,
              3
            ],
            "details": "Create useWebSocket.ts custom hook exporting connection state and progress data. Use useState for connectionState (connecting/connected/disconnecting/disconnected), progressState (array of 7 steps with id, name, status, progress, subItems, duration), currentStep (1-7 or null), generationId, qualityScore. Implement useEffect to initialize WebSocket connection on mount and cleanup on unmount. Subscribe to all 7 event types using websocketService handlers. Use useCallback for event handler functions to prevent unnecessary re-renders: handleConnectionEstablished, handleGenerationStarted, handleStepStart, handleStepProgress, handleStepComplete, handleGenerationComplete, handleError. Update progressState immutably on each event using setState with functional updates. Implement proper cleanup: unsubscribe all event listeners, disconnect socket if component unmounts mid-generation. Return hook interface: { connectionState, progressState, currentStep, generationId, qualityScore, isConnected, error, startGeneration, disconnect }. Handle edge cases: rapid mount/unmount, multiple hook instances, connection state race conditions.",
            "status": "pending",
            "testStrategy": "Test hook initializes connection on mount and cleans up on unmount. Verify no memory leaks by mounting/unmounting 10 times and checking listener count. Send mock events and verify progressState updates correctly for all 7 steps. Test useCallback prevents unnecessary re-renders using React DevTools Profiler. Verify connectionState transitions correctly through all states.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "HTTP Polling Fallback Mechanism with 1-Second Intervals",
            "description": "Implement HTTP polling fallback that activates after WebSocket max retries, polling /api/generation-status every 1 second with proper error handling and automatic stop conditions.",
            "dependencies": [
              2,
              4
            ],
            "details": "Create pollingService.ts implementing HTTP polling fallback. Listen for 'max_retries_exceeded' event from websocketService to trigger polling activation. Implement polling loop using setInterval with 1000ms interval calling GET /api/generation-status?generationId={id}. Parse polling response and transform to match WebSocket event format (step_start, step_progress, step_complete, generation_complete). Dispatch transformed events to same handlers used by WebSocket. Implement stop conditions: generation_complete received, error state reached, manual cancellation, component unmount. Add polling state management: isPolling boolean, pollingInterval reference for cleanup. Implement exponential backoff for polling errors (don't hammer failing endpoint): increase interval to 2s, 5s, 10s on consecutive failures. Show user notification when falling back to polling mode. Automatically attempt to reconnect WebSocket every 30 seconds while polling (in case network recovers). Clean up interval on stop. Handle edge cases: stale generationId, backend returns 404, concurrent polling prevention.",
            "status": "pending",
            "testStrategy": "Trigger max_retries_exceeded and verify polling starts automatically. Mock /api/generation-status endpoint and verify requests occur every 1 second. Test polling stops on generation_complete. Verify polling transforms responses to WebSocket event format correctly. Test exponential backoff on polling errors increases intervals. Verify no memory leaks from uncleaned intervals.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "SessionStorage Integration for Progress Persistence Across Refreshes",
            "description": "Implement sessionStorage persistence to save and restore progress state, allowing users to refresh the page mid-generation without losing progress.",
            "dependencies": [
              4
            ],
            "details": "Create storageService.ts utility for sessionStorage operations with error handling. Define storage key: 'websocket_progress_state'. Implement saveProgressState function serializing: progressState (7 steps with all details), currentStep, generationId, qualityScore, timestamp, connectionState. Use JSON.stringify with error handling for circular references. Implement loadProgressState function with JSON.parse and validation. In useWebSocket hook, add useEffect to save state to sessionStorage on every progressState update (debounced to avoid excessive writes - max once per 500ms). On hook initialization, check sessionStorage for existing state before connecting. If found and timestamp < 1 hour old, restore state and resume connection/polling. Clear sessionStorage on generation_complete or error. Handle edge cases: sessionStorage quota exceeded (catch and log), corrupted data (validate and clear), multiple tabs (use generationId to prevent conflicts), private browsing mode (sessionStorage may be disabled). Implement storage event listener to sync state across tabs if needed.",
            "status": "pending",
            "testStrategy": "Start generation, refresh page mid-generation, verify progress state is restored correctly. Test all 7 steps persist and restore properly. Verify sessionStorage is cleared on generation_complete. Test quota exceeded scenario with large state object. Verify corrupted sessionStorage data is handled gracefully. Test state older than 1 hour is ignored and cleared.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Divide WebSocket implementation into: 1) Socket.io-client setup with connection configuration and environment variables, 2) Auto-reconnect logic with exponential backoff (1s initial, 30s max, 1.5x multiplier, jitter), 3) Event handler implementation for 7 event types (connection_established, generation_started, step_start, step_progress, step_complete, generation_complete, error), 4) useWebSocket custom hook with connection state management and cleanup, 5) HTTP polling fallback mechanism with 1-second intervals, 6) SessionStorage integration for progress persistence across page refreshes. Each subtask should handle edge cases and connection failures gracefully.",
        "updatedAt": "2026-02-12T20:59:22.909Z"
      },
      {
        "id": "15",
        "title": "Progress Display Component with Collapsible Steps",
        "description": "Build ProgressDisplay and ProgressStep components with cursor-style collapsible behavior, smooth animations, educational details, and auto-collapse timing. Render all 7 generation steps with icons from lucide-react.",
        "details": "Create ProgressDisplay.tsx component to manage overall progress flow across 7 steps: Input Processing, Keyword Research, Multi-Source Research, Content Generation, Schema Markup, Quality Validation, Saving Files. For each step, use appropriate lucide-react icon (Search, BookOpen, FileText, Tag, CheckCircle, Save). Create ProgressStep.tsx sub-component with 4 visual states: Pending (gray Pause icon, collapsed), Processing (yellow Loader spinner, expanded, yellow glow), Complete expanded (green CheckCircle, all details shown), Complete collapsed (green CheckCircle with summary only). Implement expand/collapse with CSS transitions (300ms) using Tailwind classes or styled-components. Rotate ChevronDown icon 180deg on expand. Display sub-items with staggered animation (each appears 100-200ms apart) using CSS animation or React Framer Motion. Auto-collapse 3 seconds after step_complete event using setTimeout (reset if user manually expands). Store expanded/collapsed state per step so user interactions persist during generation. Display detailed educational information when expanded showing metrics, counts, and status. Apply Mesa yellow (#f9c65d) for active states, green (#10b981) for complete, gray (#9ca3af) for pending. Ensure no layout shifts or jank during animations (use transform/opacity, not width/height).",
        "testStrategy": "Verify all 7 steps render with correct icons from lucide-react (no emojis). Test step transitions from pending  processing  complete with smooth animations. Verify auto-collapse triggers exactly 3 seconds after step_complete event. Test manual expand/collapse by clicking steps during generation - verify state persists and toggles correctly. Verify sub-items appear one-by-one with staggered timing. Test on 60fps using Chrome DevTools Performance tab - no frame drops during animations. Test on mobile viewport to ensure no overflow. Verify color transitions match Mesa brand colors exactly.",
        "priority": "high",
        "dependencies": [
          "14"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "ProgressDisplay.tsx Container Component with State Orchestration",
            "description": "Create the main ProgressDisplay.tsx container component that manages the overall progress flow across all 7 generation steps with proper state management and event handling.",
            "dependencies": [],
            "details": "Build ProgressDisplay.tsx component that renders all 7 steps: Input Processing, Keyword Research, Multi-Source Research, Content Generation, Schema Markup, Quality Validation, Saving Files. Implement state management to track current step, completion status, and expanded/collapsed state for each step. Map each step to appropriate lucide-react icons (Search, BookOpen, Globe, FileText, Tag, CheckCircle, Save). Subscribe to WebSocket events (step_start, step_progress, step_complete) from Task 14 to update step states. Pass step data and callbacks to ProgressStep children. Ensure 60fps performance with React.memo and proper re-render optimization.",
            "status": "pending",
            "testStrategy": "Verify all 7 steps render in correct order with proper lucide-react icons. Test state updates when receiving WebSocket events. Verify no unnecessary re-renders using React DevTools Profiler. Confirm 60fps performance during state transitions.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "ProgressStep.tsx Sub-Component with 4 Visual States",
            "description": "Create ProgressStep.tsx sub-component implementing 4 distinct visual states with proper icon mapping and Mesa brand color application.",
            "dependencies": [
              1
            ],
            "details": "Build ProgressStep.tsx with 4 visual states: 1) Pending - gray (#9ca3af) Pause icon, collapsed view with minimal info, 2) Processing - yellow (#f9c65d) Loader spinner with rotation animation, expanded view with yellow glow effect, 3) Complete Expanded - green (#10b981) CheckCircle icon, all educational details and metrics visible, 4) Complete Collapsed - green CheckCircle with summary only. Accept props: stepId, title, icon, status, details, metrics, isExpanded, onToggle. Render appropriate icon based on state. Display educational information including sub-items, counts, and status when expanded. Use semantic HTML with proper ARIA attributes for accessibility.",
            "status": "pending",
            "testStrategy": "Test all 4 visual states render correctly with proper colors and icons. Verify Pending shows gray Pause, Processing shows yellow Loader with spin, Complete shows green CheckCircle. Confirm educational details display only when expanded. Test ARIA attributes for screen reader compatibility.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Expand/Collapse Animation System with CSS Transitions",
            "description": "Implement smooth expand/collapse animations using CSS transitions with ChevronDown rotation and zero layout shift using transform/opacity only.",
            "dependencies": [
              2
            ],
            "details": "Create animation system using Tailwind CSS transitions or styled-components with 300ms duration and ease-in-out timing. Implement ChevronDown icon rotation from 0deg to 180deg on expand using CSS transform. Use transform and opacity properties exclusively (no width/height changes) to prevent layout shifts and ensure 60fps performance. Apply transition-transform and transition-opacity classes. Create collapsible content wrapper with max-height: 0 when collapsed and max-height: fit-content when expanded, but animate using transform: scaleY() and transform-origin: top for smooth effect. Add will-change: transform hint for GPU acceleration. Ensure animations are hardware-accelerated and maintain 60fps.",
            "status": "pending",
            "testStrategy": "Verify expand/collapse animations complete in exactly 300ms. Test ChevronDown rotates smoothly 180 degrees. Confirm no layout shifts occur during animation using Chrome DevTools Layout Shift detection. Monitor frame rate during animations to ensure consistent 60fps. Test on lower-end devices for performance.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Auto-Collapse Timing Logic with User Interaction Persistence",
            "description": "Implement auto-collapse functionality that triggers 3 seconds after step_complete event while respecting and persisting user manual interactions.",
            "dependencies": [
              2,
              3
            ],
            "details": "Create auto-collapse logic using setTimeout that triggers exactly 3 seconds after receiving step_complete event from WebSocket. Store per-step state tracking: autoCollapseTimer (timeout ID), userHasInteracted (boolean flag), isExpanded (current state). When step_complete fires, set 3-second timer only if user hasn't manually interacted with that step. Clear existing timer if step is manually expanded/collapsed by user. Set userHasInteracted flag to true on manual toggle to prevent auto-collapse. Reset timer if user expands during countdown. Use useRef to store timer IDs and prevent memory leaks. Implement cleanup in useEffect return to clear all timers on unmount. Maintain expanded/collapsed state in component state or context so user preferences persist during generation.",
            "status": "pending",
            "testStrategy": "Verify auto-collapse triggers exactly 3 seconds after step_complete event. Test that manual user expand/collapse prevents auto-collapse for that step. Confirm timer resets if user expands during countdown. Test multiple steps completing simultaneously handle timers independently. Verify no memory leaks by checking timer cleanup on unmount.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Sub-Item Staggered Animation Implementation",
            "description": "Create staggered animation system for sub-items that appear sequentially with 100-200ms delays using CSS animations or Framer Motion while maintaining 60fps performance.",
            "dependencies": [
              3
            ],
            "details": "Implement staggered animation for sub-items (metrics, counts, status details) within expanded steps. Use CSS animation-delay property with incremental 100-200ms delays for each sub-item, or implement with Framer Motion's staggerChildren feature. Apply fade-in and slide-up effect using opacity: 0 to 1 and transform: translateY(10px) to translateY(0). Calculate delay dynamically based on item index: delay = index * 150ms. Use CSS @keyframes for fade-slide-up animation or Framer Motion variants. Ensure animations use transform and opacity only for GPU acceleration. Apply Mesa yellow (#f9c65d) highlights to active/processing items, green (#10b981) to completed items. Optimize with will-change: transform, opacity and contain: layout style paint for performance isolation. Test with 10+ sub-items to ensure smooth 60fps performance.",
            "status": "pending",
            "testStrategy": "Verify sub-items appear with staggered timing (100-200ms apart). Confirm fade-in and slide-up animations are smooth. Test with varying numbers of sub-items (3, 7, 10+) to ensure consistent performance. Monitor frame rate stays at 60fps during staggered animations. Verify Mesa brand colors apply correctly to different states.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Break down progress display into: 1) ProgressDisplay.tsx container component managing 7 steps with proper state orchestration, 2) ProgressStep.tsx sub-component with 4 visual states (pending, processing, complete-expanded, complete-collapsed) and icon mapping, 3) Expand/collapse animation system with CSS transitions (300ms), ChevronDown rotation, and no layout shift, 4) Auto-collapse timing logic (3-second setTimeout after step_complete) with user interaction persistence, 5) Sub-item staggered animation implementation (100-200ms delays) with Mesa brand color application. Each subtask should maintain 60fps performance.",
        "updatedAt": "2026-02-12T21:05:28.505Z"
      },
      {
        "id": "16",
        "title": "Output Display and File Download System",
        "description": "Build OutputDisplay component showing generation results, quality score, download options. Implement downloadService for individual file downloads and client-side ZIP creation using jszip. Create all 8 file types with proper formatting.",
        "details": "Create OutputDisplay.tsx component displaying: Summary card (topic title, input type badge, quality score 0-100 with color coding: green 80+, yellow 60-79, red <60), generation time, primary keyword. Create download section with prominent 'Download All Assets' button (Mesa yellow, Download icon, full width or prominent). Display 8 individual download buttons in 2-column grid (blog-post.html, youtube-script.txt, youtube-metadata.json, schema-markup.json, image-prompts.txt, seo-report.json, research-sources.json, metadata.json). Add WordPress status badge if applicable with link to draft. Include 'Next Steps' guidance with numbered list and lucide-react icons. Add 'Generate Another' button with RotateCw icon. Create downloadService.ts using jszip 3.10.1 for client-side ZIP creation. Implement ZIP filename format: mgc-content-[slug]-[YYYYMMDD-HHMMSS].zip. ZIP structure includes all 8 files plus README.txt with usage instructions. For individual downloads, use axios to fetch from /api/output/[filename] endpoints. Implement Blob download using File API (create ObjectURL, create anchor element, trigger click, revoke URL after 1 second using setTimeout). Handle MIME types correctly for each file type (text/html, text/plain, application/json). Add file sizes to buttons (e.g., '12.4 KB').",
        "testStrategy": "Verify quality score displays with correct colors at boundaries (79 yellow, 80 green, 59 red). Test Download All creates valid ZIP file containing all 8 files with correct structure. Verify ZIP filename includes timestamp and slug. Test individual downloads for all 8 file types - verify files download with correct extensions and content. Test ZIP creation performance - should complete < 2 seconds. Verify README.txt content is accurate. Test on multiple browsers (Chrome, Safari, Firefox, Edge) to ensure download compatibility. Verify no page reload or navigation on download. Test with large files (simulate 5MB files) to ensure no UI freezing.",
        "priority": "high",
        "dependencies": [
          "15"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create OutputDisplay.tsx component with summary card and quality score display",
            "description": "Build the main OutputDisplay component with summary card showing topic title, input type badge, quality score with color-coded display (green 80+, yellow 60-79, red <60), generation time, and primary keyword.",
            "dependencies": [],
            "details": "Create OutputDisplay.tsx in src/components with TypeScript. Implement summary card layout with topic title heading, input type badge component, quality score display (0-100 range) with conditional color coding logic (green for 80+, yellow for 60-79, red for <60). Display generation time in human-readable format (e.g., '2m 34s'). Show primary keyword prominently. Add WordPress status badge conditionally with link to draft if applicable. Use Tailwind CSS for styling with proper spacing and typography. Import lucide-react icons as needed.",
            "status": "pending",
            "testStrategy": "Verify quality score displays with correct colors at exact boundaries: test score 79 shows yellow, 80 shows green, 59 shows red, 60 shows yellow. Test with various generation times and verify formatting. Confirm WordPress badge only appears when applicable with correct link.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Build download section UI with Download All button and 8 individual file buttons",
            "description": "Create the download section interface with prominent 'Download All Assets' button and 8 individual download buttons arranged in a 2-column grid layout.",
            "dependencies": [
              1
            ],
            "details": "Within OutputDisplay.tsx, create download section with 'Download All Assets' button styled in Mesa yellow with Download icon from lucide-react, full width or prominent placement. Below that, create 2-column grid displaying 8 individual download buttons: blog-post.html, youtube-script.txt, youtube-metadata.json, schema-markup.json, image-prompts.txt, seo-report.json, research-sources.json, metadata.json. Each button should display file name, file size (e.g., '12.4 KB'), and appropriate icon. Add 'Next Steps' guidance section with numbered list and lucide-react icons. Include 'Generate Another' button with RotateCw icon. Use responsive grid that adapts to mobile (single column on small screens).",
            "status": "pending",
            "testStrategy": "Verify all 8 download buttons render in 2-column grid on desktop and single column on mobile. Test Download All button prominence and Mesa yellow styling. Confirm file sizes display correctly for each button. Verify all icons render from lucide-react. Test Generate Another button functionality.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement downloadService.ts with jszip integration for client-side ZIP creation",
            "description": "Create downloadService.ts service module implementing client-side ZIP file creation using jszip 3.10.1 library with proper file bundling and compression.",
            "dependencies": [],
            "details": "Create downloadService.ts in src/services. Install and import jszip 3.10.1. Implement createZipArchive function that accepts all 8 file contents as parameters. Add each file to ZIP with correct paths and content. Generate README.txt with usage instructions for all files. Implement proper error handling for ZIP creation failures. Ensure ZIP creation completes within <2s performance target by using appropriate compression levels. Export functions for both ZIP creation and individual file downloads. Use async/await pattern for asynchronous operations.",
            "status": "pending",
            "testStrategy": "Test ZIP creation with all 8 files and verify valid ZIP structure. Measure ZIP creation time with various file sizes to ensure <2s target is met. Verify README.txt is included with correct content. Test error handling with invalid file content. Verify ZIP can be extracted successfully with standard tools.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement ZIP filename generation and structure with timestamp and slug",
            "description": "Create ZIP file naming logic following format mgc-content-[slug]-[YYYYMMDD-HHMMSS].zip and ensure proper file structure within the archive including README.txt generation.",
            "dependencies": [
              3
            ],
            "details": "Within downloadService.ts, implement generateZipFilename function that creates filename in format: mgc-content-[slug]-[YYYYMMDD-HHMMSS].zip. Generate slug from topic title (lowercase, hyphenated, max 50 chars). Format timestamp as YYYYMMDD-HHMMSS using current date/time. Implement generateReadme function that creates README.txt content with: file descriptions, usage instructions for each file type, WordPress import instructions, and next steps guidance. Ensure ZIP structure is flat (all files in root) for easy access. Handle special characters in slug properly.",
            "status": "pending",
            "testStrategy": "Verify ZIP filename follows exact format with correct slug generation from various topic titles. Test timestamp format is YYYYMMDD-HHMMSS. Verify README.txt contains all required sections. Test slug generation with special characters, long titles, and edge cases. Confirm ZIP structure is flat with all files in root.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create individual file download logic using Blob API with proper MIME types",
            "description": "Implement individual file download functionality for all 8 file types using Blob API with correct MIME type handling and ObjectURL management for cross-browser compatibility.",
            "dependencies": [
              3
            ],
            "details": "In downloadService.ts, implement downloadFile function that accepts filename, content, and MIME type. Create Blob with appropriate MIME type for each file: text/html for .html, text/plain for .txt, application/json for .json files. Implement download trigger using File API: create ObjectURL from Blob, create invisible anchor element, set href to ObjectURL, set download attribute to filename, trigger click event, revoke ObjectURL after 1 second using setTimeout for cleanup. Ensure cross-browser compatibility (Chrome, Safari, Firefox, Edge). Handle special characters in filenames. Add error handling for download failures.",
            "status": "pending",
            "testStrategy": "Test individual downloads for all 8 file types and verify correct MIME types. Verify files download with correct names and content. Test in Chrome, Safari, Firefox, and Edge browsers. Verify ObjectURL is properly revoked after download. Test with large files and special characters in filenames. Confirm no memory leaks from unreleased ObjectURLs.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Implement file size calculation and display with download button integration",
            "description": "Create file size calculation utility and integrate with download buttons to display human-readable file sizes for all 8 file types with proper formatting.",
            "dependencies": [
              2,
              5
            ],
            "details": "In downloadService.ts, implement calculateFileSize function that computes byte size from file content (string or JSON). Create formatFileSize utility that converts bytes to human-readable format (B, KB, MB) with 1 decimal place (e.g., '12.4 KB'). Integrate file size calculation into OutputDisplay component to display sizes on each of the 8 download buttons. Calculate sizes when content is available and update button labels. Handle edge cases like empty files or very large files. Ensure size calculation is performant and doesn't block UI. Cache calculated sizes to avoid recalculation.",
            "status": "pending",
            "testStrategy": "Verify file sizes display correctly for all 8 file types with proper units (B, KB, MB). Test size calculation accuracy with known file sizes. Verify formatting shows 1 decimal place. Test with empty files, small files (<1KB), and large files (>1MB). Confirm size calculation performance doesn't impact UI responsiveness. Verify sizes update correctly when content changes.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Divide output and download system into: 1) OutputDisplay.tsx component with summary card (quality score color coding, generation time, primary keyword display), 2) Download section UI with 'Download All Assets' button and 8 individual file buttons in 2-column grid, 3) downloadService.ts implementation with jszip 3.10.1 for client-side ZIP creation, 4) ZIP file structure and naming (mgc-content-[slug]-[YYYYMMDD-HHMMSS].zip) with README.txt generation, 5) Individual file download logic using Blob API with proper MIME types for 8 file types, 6) File size calculation and display with cross-browser download compatibility. Each subtask should complete within performance targets (<2s for ZIP creation).",
        "updatedAt": "2026-02-12T21:07:02.024Z"
      },
      {
        "id": "17",
        "title": "Error Handling, Validation, and User Feedback System",
        "description": "Implement comprehensive error handling for API failures, WebSocket disconnections, validation errors, and rate limiting. Create ErrorDisplay component with user-friendly messages and recovery options. Handle all error states gracefully.",
        "details": "Create ErrorDisplay.tsx component for displaying errors with user-friendly messages (no stack traces or technical jargon). Implement error types: API key missing (show which key, link to config), rate limit exceeded (show retry countdown, suggest wait time), network errors (retry button with countdown auto-retry in 10s), generation quality low (warning not error, show quality score < 80 with specific issues), WebSocket disconnected (auto-reconnect indicator). Use lucide-react icons: AlertTriangle for warnings, XCircle for errors, Info for messages. Implement error recovery options: Retry button, Skip button (for optional features), Cancel button. Create error boundaries to catch React component errors and display user-friendly UI. Log errors to console for debugging without showing to user. Implement axios interceptors for handling HTTP errors consistently across all API calls (see [34] for best practices). Add validation feedback: show specific issues (e.g., 'Only 1,200 words - target 1,500+') rather than generic 'Invalid input'. For low quality scores, show suggestions for improvement. Implement graceful degradation - allow generation to proceed without optional APIs (e.g., proceed without DataForSEO if key missing). Add connection status indicator showing WebSocket state. Use amber (#f59e0b) for warnings, red (#ef4444) for errors.",
        "testStrategy": "Trigger each error type and verify appropriate message displays. Test API key missing error - verify specific key is identified and recovery link shown. Test rate limit error - verify countdown timer functions correctly, auto-retry works. Test network error - verify retry button appears, countdown shows. Simulate WebSocket disconnection - verify auto-reconnect indicator shows, attempts up to 3 times, falls back to polling. Test low quality warning - verify score displays with suggestions. Verify error messages are under-40 words and actionable. Test error boundary by intentionally throwing component error - verify fallback UI shown, doesn't crash entire app. Verify errors logged to console for debugging.",
        "priority": "high",
        "dependencies": [
          "12",
          "14"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create ErrorDisplay.tsx Component with User-Friendly Messaging",
            "description": "Build the ErrorDisplay component with lucide-react icons (AlertTriangle for warnings, XCircle for errors, Info for messages) and user-friendly error messages without technical jargon or stack traces.",
            "dependencies": [],
            "details": "Create ErrorDisplay.tsx component that accepts error type, message, and optional details as props. Implement icon mapping using lucide-react: AlertTriangle (amber #f59e0b) for warnings, XCircle (red #ef4444) for errors, Info for informational messages. Design clean UI layout with icon, title, and description under 40 words. Ensure no technical stack traces are shown to users. Style component with Tailwind CSS using appropriate color schemes.",
            "status": "pending",
            "testStrategy": "Render ErrorDisplay with each error type (warning, error, info) and verify correct icon displays with appropriate colors. Verify messages are user-friendly and under 40 words. Test that no technical details or stack traces appear in the UI.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Specific Error Type Handlers with Recovery Options",
            "description": "Implement all error type handlers including API key missing, rate limit exceeded with countdown, network errors with auto-retry, quality warnings, and WebSocket disconnection with auto-reconnect indicator.",
            "dependencies": [
              1
            ],
            "details": "Create error type implementations: API key missing (show specific key name, link to config page), rate limit exceeded (countdown timer showing retry time, suggest wait duration), network errors (retry button with 10s countdown auto-retry), generation quality low (warning with quality score < 80 and specific improvement suggestions), WebSocket disconnected (auto-reconnect indicator with connection status). Each error should provide actionable feedback under 40 words with specific details about the issue.",
            "status": "pending",
            "testStrategy": "Trigger each error type manually and verify correct message displays. Test API key error shows specific key name. Verify rate limit countdown functions correctly. Test network error auto-retry triggers after 10 seconds. Verify quality warnings show score and suggestions. Test WebSocket reconnect indicator updates.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build Error Recovery Mechanisms with Action Buttons",
            "description": "Implement error recovery action buttons (Retry, Skip, Cancel) with countdown timers and appropriate handlers for each error type to enable user-driven recovery.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create recovery button components: Retry button (triggers API call retry or reconnection attempt), Skip button (allows bypassing optional features like DataForSEO), Cancel button (stops current operation). Implement countdown timers for auto-retry scenarios (10s for network errors). Add button state management to prevent duplicate actions. Style buttons with clear visual hierarchy and disabled states during countdown. Connect buttons to appropriate error recovery logic for each error type.",
            "status": "pending",
            "testStrategy": "Test Retry button triggers appropriate recovery action for each error type. Verify Skip button allows generation to proceed without optional APIs. Test Cancel button stops current operation. Verify countdown timers display correctly and auto-trigger retry after timeout. Test button disabled states during countdown.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement React Error Boundaries for Component Error Catching",
            "description": "Create React Error Boundary components to catch component errors and display fallback UI instead of crashing the application, with error logging to console for debugging.",
            "dependencies": [
              1
            ],
            "details": "Create ErrorBoundary.tsx component using React's componentDidCatch and getDerivedStateFromError lifecycle methods. Implement fallback UI using ErrorDisplay component to show user-friendly error message when component errors occur. Log full error details and component stack to console for debugging without exposing to users. Wrap key application sections (generation flow, progress display, results) with error boundaries. Provide recovery option to reset error boundary state and retry rendering.",
            "status": "pending",
            "testStrategy": "Simulate component errors by throwing errors in child components. Verify Error Boundary catches errors and displays fallback UI instead of crashing. Verify error details are logged to console. Test recovery option resets boundary and re-renders component. Verify nested boundaries work correctly.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Configure Axios Interceptors and Graceful Degradation Logic",
            "description": "Set up axios interceptors for consistent HTTP error handling across all API calls and implement graceful degradation to allow generation to proceed without optional APIs.",
            "dependencies": [
              2
            ],
            "details": "Configure axios request and response interceptors in a central configuration file. Implement response interceptor to catch HTTP errors (4xx, 5xx) and transform them into user-friendly error objects. Map common HTTP status codes to specific error types (401/403 for API key issues, 429 for rate limiting, 5xx for server errors). Implement graceful degradation logic to mark optional APIs (DataForSEO) as skippable and allow generation to continue. Add connection status indicator for WebSocket state. Follow best practices from task 34 for interceptor implementation.",
            "status": "pending",
            "testStrategy": "Test axios interceptor catches and transforms HTTP errors consistently. Verify 401/403 errors show API key missing message. Test 429 errors trigger rate limit handler with countdown. Verify generation proceeds when optional API keys are missing. Test connection status indicator reflects WebSocket state accurately.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Break down error handling into: 1) ErrorDisplay.tsx component with user-friendly messaging and lucide-react icons (AlertTriangle, XCircle, Info), 2) Error type implementations (API key missing, rate limit with countdown, network errors with auto-retry, quality warnings, WebSocket disconnection), 3) Error recovery mechanisms (Retry, Skip, Cancel buttons with countdown timers), 4) React Error Boundaries for component error catching with fallback UI, 5) Axios interceptors for consistent HTTP error handling and graceful degradation logic. Each subtask should provide actionable feedback under 40 words.",
        "updatedAt": "2026-02-12T21:09:02.510Z"
      },
      {
        "id": "18",
        "title": "Mesa Group Branding, Styling, and Responsive Design Implementation",
        "description": "Apply Mesa Group brand colors and typography throughout UI. Replace all emojis with lucide-react icons. Implement responsive design for desktop (1024px+), tablet (768-1023px), and mobile viewports. Ensure cross-browser compatibility.",
        "details": "Apply Mesa Group Tailwind color configuration (already in Nano Banana config): primary yellow #f9c65d, secondary gold #bb9446, cream #f8d899, dark gray #3e3e3e, medium gray #6b7280, light gray #f5f5f5. Implement status colors: success #10b981, processing #f9c65d, pending #9ca3af, warning #f59e0b, error #ef4444. Use Inter font (already configured from Nano Banana) with weights 400/600/700. Verify NO emojis anywhere in codebase - replace all with lucide-react icons (Zap for banana/processing, Search for search, TrendingUp for data/charts, Brain for AI, Video for video, FileText for documents, Tag for tags, CheckCircle for success, Loader for loading, XCircle for errors, AlertTriangle for warnings, Download for downloads, Globe for web, FolderOpen for folders, RotateCw for repeat, Image for images). Implement responsive layouts using Tailwind breakpoints: sm (640px), md (768px), lg (1024px). Desktop layout: 1200px max-width centered, 70% input width, 2-column download grid. Tablet layout: 768px max-width, 90% input width, 2-column grid. Mobile layout: full width, 1-column grid, stacked buttons. Use Tailwind utilities (not custom CSS) for responsive behavior. Ensure 48px+ touch targets on tablet. Test typography scaling for readability on all viewports. Implement hover states with Mesa Gold (#bb9446). Verify box shadows and border radius consistent (8px for cards, 12px for buttons).",
        "testStrategy": "Audit entire codebase for emojis using grep/search - result should be zero. Verify all icons are from lucide-react library by checking imports. Test Mesa colors render correctly using browser color picker - spot check 5+ color values. Test responsive layout at breakpoints: 1920x1080 (desktop), 768x1024 (tablet), 375x667 (mobile) using Chrome DevTools device emulation. Verify no horizontal scrolling at any viewport. Measure text sizes at each breakpoint - should remain readable. Test touch target sizes on mobile - buttons should be  48px. Test on Chrome, Safari, Firefox, Edge - verify fonts load correctly, colors match, layout displays properly. Verify Tailwind classes used (not inline styles). Performance audit - ensure CSS is optimized, no unused classes.",
        "priority": "medium",
        "dependencies": [
          "15",
          "16",
          "17"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Mesa Group Color Palette and Typography Application",
            "description": "Apply Mesa Group brand colors throughout the UI including primary yellow, secondary gold, cream, gray shades, and status colors. Configure Inter font with proper weights across all components.",
            "dependencies": [],
            "details": "Apply Mesa Group Tailwind color configuration: primary yellow #f9c65d, secondary gold #bb9446, cream #f8d899, dark gray #3e3e3e, medium gray #6b7280, light gray #f5f5f5. Implement status colors: success #10b981, processing #f9c65d, pending #9ca3af, warning #f59e0b, error #ef4444. Use Inter font with weights 400/600/700. Apply hover states with Mesa Gold (#bb9446). Ensure consistent box shadows and border radius (8px for cards, 12px for buttons). Update all buttons, cards, backgrounds, text colors, and interactive elements to use the Mesa Group palette.",
            "status": "pending",
            "testStrategy": "Use browser color picker to verify 5+ color values match exact hex codes. Test hover states on interactive elements show Mesa Gold. Verify Inter font loads correctly in Chrome, Safari, Firefox, Edge. Check border radius consistency on cards (8px) and buttons (12px) using browser inspector.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Complete Emoji to Lucide-React Icon Replacement Audit",
            "description": "Conduct comprehensive codebase audit to identify and replace all emojis with appropriate lucide-react icons. Map 15+ icon types to their corresponding lucide-react components.",
            "dependencies": [
              1
            ],
            "details": "Perform codebase-wide search for emojis using grep/regex patterns. Replace all emojis with lucide-react icons: Zap for banana/processing, Search for search, TrendingUp for data/charts, Brain for AI, Video for video, FileText for documents, Tag for tags, CheckCircle for success, Loader for loading, XCircle for errors, AlertTriangle for warnings, Download for downloads, Globe for web, FolderOpen for folders, RotateCw for repeat, Image for images. Verify all icon imports are from lucide-react library. Ensure consistent icon sizing and color inheritance.",
            "status": "pending",
            "testStrategy": "Run grep/search commands across entire codebase for emoji unicode ranges and common emoji characters - result must be zero matches. Verify all icon imports come from 'lucide-react' package by checking import statements. Manually review all UI screens to confirm no visual emojis remain. Test icon rendering in all browsers.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Responsive Layout Implementation with Tailwind Breakpoints",
            "description": "Implement responsive layouts for desktop (1024px+), tablet (768-1023px), and mobile viewports using Tailwind breakpoints. Configure grid systems, column layouts, and component sizing for each breakpoint.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement responsive layouts using Tailwind breakpoints: sm (640px), md (768px), lg (1024px). Desktop layout: 1200px max-width centered, 70% input width, 2-column download grid. Tablet layout: 768px max-width, 90% input width, 2-column grid. Mobile layout: full width, 1-column grid, stacked buttons. Use only Tailwind utilities (no custom CSS) for responsive behavior. Implement proper spacing, padding, and margin adjustments for each viewport. Test typography scaling for readability across all viewports.",
            "status": "pending",
            "testStrategy": "Test responsive layout at specific breakpoints: 1920x1080 (desktop), 768x1024 (tablet), 375x667 (mobile). Verify desktop shows 1200px max-width centered, 70% input width, 2-column grid. Verify tablet shows 768px max-width, 90% input width, 2-column grid. Verify mobile shows full width, 1-column grid, stacked buttons. Use browser DevTools to confirm no custom CSS is used, only Tailwind classes.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Cross-Browser Compatibility and Touch Target Optimization",
            "description": "Ensure cross-browser compatibility across Chrome, Safari, Firefox, and Edge. Optimize touch targets to meet 48px+ minimum size requirement for tablet and mobile devices.",
            "dependencies": [
              3
            ],
            "details": "Test all UI components and layouts in Chrome, Safari, Firefox, and Edge browsers. Verify font loading, color accuracy, and layout consistency across browsers. Ensure all interactive elements (buttons, links, form inputs) have minimum 48px touch targets on tablet and mobile viewports. Add appropriate padding/spacing to meet touch target requirements. Test hover states work on desktop and touch interactions work on mobile/tablet. Verify visual consistency and accessibility standards are maintained across all browsers and devices.",
            "status": "pending",
            "testStrategy": "Test in Chrome, Safari, Firefox, Edge on both desktop and mobile/tablet viewports. Use browser inspector to measure touch target sizes - all interactive elements must be 48px+ on tablet/mobile. Test font rendering and color accuracy in each browser using color picker. Perform manual interaction testing on actual mobile/tablet devices. Run accessibility audit tools to verify WCAG compliance for touch targets and color contrast.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Divide branding and responsive design into: 1) Mesa Group color palette application throughout UI (primary yellow #f9c65d, secondary gold #bb9446, status colors) with Inter font configuration, 2) Complete emoji-to-lucide-react icon replacement audit and implementation (15+ icon types mapped), 3) Responsive layout implementation using Tailwind breakpoints (desktop 1024px+, tablet 768-1023px, mobile) with proper grid/column adjustments, 4) Cross-browser compatibility testing and touch target optimization (48px+ on tablet/mobile). Each subtask should maintain visual consistency and accessibility standards.",
        "updatedAt": "2026-02-12T21:20:12.882Z"
      },
      {
        "id": "19",
        "title": "Integration Testing, Performance Optimization, and Production Readiness",
        "description": "Perform end-to-end integration testing with real backend, optimize performance metrics, ensure cross-browser compatibility, prepare deployment configuration, and validate all acceptance criteria.",
        "details": "Execute full integration tests with FastAPI backend running locally. Test complete workflows: 1) Paste ATP question  Generate  receive all 7 progress steps  see results with quality score  download ZIP successfully, 2) Paste YouTube URL  Generate  verify video-specific metadata, 3) Paste competitor URL  Generate  verify research sources populated, 4) Paste plain topic  Generate  verify keyword research populated. Generate 5 complete content pieces with various input types and verify all outputs are usable (HTML opens in browser, TXT readable, JSON parses). Performance optimization: measure page load time (target < 2s using Lighthouse), WebSocket latency (target < 500ms), ZIP creation time (target < 2s), memory usage (no leaks during 10+ min generation). Use Chrome DevTools Performance tab to profile and optimize. Implement code splitting for ProgressDisplay and OutputDisplay components using React.lazy() and Suspense. Set up environment-specific builds (dev vs production). Create .env.production with optimized settings. Set up Vercel/Netlify build configuration (or chosen host). Create deployment instructions for backend (Docker or VM). Validate all 20 acceptance criteria from PRD are met. Create user guide documentation in Markdown. Set up analytics/error tracking if needed. Verify NO cost mentions appear anywhere in client-facing UI through regex search.",
        "testStrategy": "Run Lighthouse audit targeting: Performance > 90, Accessibility > 95, Best Practices > 95. Test full generation flow 5 times with different input types, verify 100% success rate. Measure WebSocket latency across 50+ messages - calculate average and p95. Profile memory usage during 10-minute generation using Chrome DevTools Memory tab - verify no sustained growth. Test cross-browser: Chrome latest, Safari latest, Firefox latest, Edge latest. Verify all 20 acceptance criteria met through manual checklist. Test deployment pipeline end-to-end. Verify .env variables work in production mode. Load test with simulated concurrent users if possible (using Apache JMeter or similar). Security check: verify no API keys in frontend code, verify CORS properly configured, verify no XSS vulnerabilities using OWASP checklist.",
        "priority": "medium",
        "dependencies": [
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "End-to-End Workflow Testing with FastAPI Backend for All Input Types",
            "description": "Execute comprehensive integration tests for all 4 input types (ATP question, YouTube URL, competitor URL, plain topic) with real FastAPI backend running locally. Verify complete workflows from input to ZIP download.",
            "dependencies": [],
            "details": "Test workflow 1: Paste ATP question  Generate  receive all 7 progress steps  see results with quality score  download ZIP successfully. Test workflow 2: Paste YouTube URL  Generate  verify video-specific metadata appears. Test workflow 3: Paste competitor URL  Generate  verify research sources populated correctly. Test workflow 4: Paste plain topic  Generate  verify keyword research populated. Generate 5 complete content pieces with various input types and verify all outputs are usable (HTML opens in browser, TXT readable, JSON parses correctly). Document test results with screenshots and logs. Pass criteria: 100% success rate across all 5 test runs, all ZIP files contain valid HTML/TXT/JSON files.",
            "status": "pending",
            "testStrategy": "Run 5 complete generation flows with different input types. Verify 100% success rate. Check that each ZIP contains valid HTML (opens in browser), TXT (readable text), and JSON (valid parse). Verify all 7 progress steps appear in correct order. Confirm quality scores display correctly.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Performance Profiling and Optimization with Metrics Validation",
            "description": "Profile application performance using Chrome DevTools and measure key metrics: page load time, WebSocket latency, ZIP creation time, and memory usage. Optimize to meet strict performance targets.",
            "dependencies": [
              1
            ],
            "details": "Use Chrome DevTools Performance tab to profile page load and identify bottlenecks. Measure and optimize page load time to target < 2s using Lighthouse. Measure WebSocket latency across 50+ messages and calculate average and p95, targeting < 500ms. Measure ZIP creation time targeting < 2s. Profile memory usage during 10+ minute generation session to detect memory leaks using Chrome DevTools Memory profiler. Take heap snapshots before, during, and after generation. Identify and fix any memory leaks or performance bottlenecks. Document baseline metrics vs optimized metrics. Pass criteria: Page load < 2s, WebSocket latency < 500ms, ZIP creation < 2s, no memory leaks detected.",
            "status": "pending",
            "testStrategy": "Run Lighthouse audit and verify Performance score. Measure WebSocket latency across 50+ messages using performance.now(). Profile memory with Chrome DevTools during 10-minute session. Take 3 heap snapshots and compare for leaks. Verify all metrics meet targets.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Code Splitting Implementation for ProgressDisplay and OutputDisplay Components",
            "description": "Implement code splitting using React.lazy() and Suspense for ProgressDisplay and OutputDisplay components to reduce initial bundle size and improve page load performance.",
            "dependencies": [
              2
            ],
            "details": "Refactor ProgressDisplay component to use React.lazy() for dynamic import. Refactor OutputDisplay component to use React.lazy() for dynamic import. Wrap lazy-loaded components with React Suspense and provide appropriate fallback UI (loading spinner or skeleton). Verify bundle size reduction using Vite build analyzer. Measure impact on initial page load time. Update imports in App.tsx or relevant parent components. Test that components load correctly when needed during generation workflow. Pass criteria: Initial bundle size reduced by at least 20%, lazy loading works without errors, fallback UI displays during component load.",
            "status": "pending",
            "testStrategy": "Build production bundle and analyze chunk sizes using vite-plugin-visualizer. Verify ProgressDisplay and OutputDisplay are in separate chunks. Test lazy loading by throttling network in DevTools. Confirm fallback UI appears briefly. Verify no runtime errors during component loading.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Production Build Configuration and Environment-Specific Settings",
            "description": "Create production-optimized build configuration with environment-specific settings, including .env.production file and Vite build optimizations for deployment.",
            "dependencies": [
              3
            ],
            "details": "Create .env.production file with optimized production settings (VITE_API_URL pointing to production backend, VITE_WS_URL for production WebSocket). Configure Vite build settings for production optimization: minification, tree-shaking, chunk size limits. Set up source maps for production debugging (hidden from public). Configure asset optimization (image compression, font subsetting if applicable). Set up environment variable validation to ensure required variables are present. Create separate .env.development and .env.production files with clear documentation. Test production build locally using `npm run build && npm run preview`. Pass criteria: Production build completes without errors, bundle size optimized, environment variables load correctly.",
            "status": "pending",
            "testStrategy": "Run `npm run build` and verify no errors. Check dist/ folder for optimized assets. Run `npm run preview` and test application with production settings. Verify environment variables load from .env.production. Check bundle size is within acceptable limits (< 500KB initial JS).",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Deployment Pipeline Setup for Frontend and Backend",
            "description": "Configure deployment pipeline for frontend (Vercel/Netlify) and create backend deployment instructions (Docker or VM setup) with complete deployment documentation.",
            "dependencies": [
              4
            ],
            "details": "Set up Vercel or Netlify project configuration (vercel.json or netlify.toml). Configure build command (`npm run build`), output directory (`dist`), and environment variables in hosting platform. Set up automatic deployments from Git repository (main branch). Create Dockerfile for FastAPI backend with multi-stage build for optimization. Write deployment instructions for backend including Docker commands or VM setup steps. Document environment variable configuration for both frontend and backend. Create deployment checklist with pre-deployment verification steps. Set up health check endpoints for backend. Pass criteria: Frontend deploys successfully to hosting platform, backend Docker image builds and runs, deployment documentation is complete and tested.",
            "status": "pending",
            "testStrategy": "Deploy frontend to Vercel/Netlify and verify application loads correctly. Test that environment variables are properly configured. Build Docker image for backend and run container locally. Verify backend health check endpoint responds. Follow deployment documentation step-by-step to ensure completeness.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Acceptance Criteria Validation Checklist for All 20 PRD Requirements",
            "description": "Systematically validate all 20 acceptance criteria from the PRD to ensure complete feature coverage and requirement fulfillment. Create comprehensive validation checklist with pass/fail status.",
            "dependencies": [
              1,
              5
            ],
            "details": "Create detailed checklist of all 20 acceptance criteria from PRD. Test each criterion systematically: input validation, generation workflow, progress tracking, output formats, error handling, UI/UX requirements, performance targets, security requirements, etc. Verify NO cost mentions appear anywhere in client-facing UI through regex search across all files (search for: price, cost, payment, billing, subscription, $, USD, etc.). Document pass/fail status for each criterion with evidence (screenshots, logs, test results). Create user guide documentation in Markdown covering: getting started, input types, generation process, output formats, troubleshooting. Set up analytics/error tracking if specified (Google Analytics, Sentry, etc.). Pass criteria: All 20 acceptance criteria pass validation, no cost mentions found in UI, user guide complete.",
            "status": "pending",
            "testStrategy": "Go through each of 20 acceptance criteria one by one. Test and document results. Run regex search across codebase for cost-related terms. Review all UI text manually. Have second person review checklist for completeness. Verify user guide covers all major features and workflows.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Cross-Browser Compatibility Testing and Lighthouse Security Audits",
            "description": "Perform comprehensive cross-browser compatibility testing across Chrome, Firefox, Safari, and Edge. Run Lighthouse audits targeting Performance >90, Accessibility >95, Best Practices >95. Verify security measures including no API keys in frontend, CORS configuration, and XSS prevention.",
            "dependencies": [
              6
            ],
            "details": "Test complete application functionality in Chrome (latest), Firefox (latest), Safari (latest), and Edge (latest). Verify UI renders correctly, WebSocket connections work, generation flows complete successfully, and ZIP downloads work in all browsers. Run Lighthouse audits in Chrome targeting: Performance > 90, Accessibility > 95, Best Practices > 95, SEO > 90. Address any issues identified by Lighthouse. Security verification: scan frontend code to ensure no API keys or secrets are exposed, verify CORS configuration on backend allows only authorized origins, test XSS prevention by attempting script injection in input fields, verify Content Security Policy headers if implemented, check OWASP Top 10 vulnerabilities. Document browser compatibility matrix and Lighthouse scores. Pass criteria: All 4 browsers fully functional, Lighthouse scores meet targets, no security vulnerabilities found.",
            "status": "pending",
            "testStrategy": "Test full generation workflow in each of 4 browsers and document results. Run Lighthouse audit 3 times and average scores. Verify Performance >90, Accessibility >95, Best Practices >95. Attempt XSS attacks in input fields. Scan code for exposed secrets using automated tools. Review CORS configuration. Create compatibility matrix showing pass/fail for each browser.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Break down integration and optimization into: 1) End-to-end workflow testing with FastAPI backend for all 4 input types (ATP question, YouTube URL, competitor URL, plain topic), 2) Performance profiling and optimization (page load <2s, WebSocket latency <500ms, ZIP creation <2s, memory leak detection), 3) Code splitting implementation for ProgressDisplay and OutputDisplay using React.lazy() and Suspense, 4) Production build configuration and environment-specific settings (.env.production, build optimization), 5) Deployment pipeline setup (Vercel/Netlify configuration, backend Docker/VM instructions), 6) Acceptance criteria validation checklist (all 20 criteria from PRD), 7) Cross-browser compatibility testing, Lighthouse audits (Performance >90, Accessibility >95, Best Practices >95), and security verification (no API keys in frontend, CORS, XSS prevention). Each subtask should include specific metrics and pass/fail criteria."
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-02-12T21:20:12.882Z",
      "taskCount": 9,
      "completedCount": 8,
      "tags": [
        "feature-content-generator"
      ]
    }
  },
  "content-generator": {
    "tasks": [
      {
        "id": 1,
        "title": "Project Setup and Environment Configuration",
        "description": "Initialize Python project structure, configure virtual environment, install dependencies, and set up configuration management with .env and config.yaml files",
        "details": "1. Create project directory structure:\n   - src/ (main source code)\n   - tests/ (unit and integration tests)\n   - output/ (generated content storage)\n   - logs/ (application logs)\n   - config/ (configuration files)\n\n2. Initialize Python 3.11+ virtual environment:\n   ```bash\n   python3.11 -m venv venv\n   source venv/bin/activate\n   ```\n\n3. Create requirements.txt with dependencies:\n   - requests>=2.31.0\n   - google-generativeai>=0.3.0\n   - pytrends>=4.9.0\n   - youtube-transcript-api>=0.6.0\n   - pydantic>=2.5.0\n   - python-dotenv>=1.0.0\n   - rich>=13.7.0\n   - pytest>=7.4.0\n   - python-wordpress-xmlrpc>=2.3\n\n4. Create .env.example template:\n   ```\n   DATAFORSEO_LOGIN=your_login\n   DATAFORSEO_PASSWORD=your_password\n   PERPLEXITY_API_KEY=your_key\n   GEMINI_API_KEY=your_key\n   YOUTUBE_API_KEY=your_key\n   JINA_API_KEY=your_key\n   WORDPRESS_URL=https://blog.mesagroupconsulting.com\n   WORDPRESS_APP_PASSWORD=your_password\n   WORDPRESS_USERNAME=evert\n   ```\n\n5. Create config.yaml for application settings:\n   ```yaml\n   generation:\n     blog_word_count_min: 1500\n     blog_word_count_max: 2500\n     script_word_count_min: 1750\n     script_word_count_max: 2500\n     timeout_research: 120\n     timeout_generation: 300\n   \n   branding:\n     company: Mesa Group Consulting\n     author: Evert Calderon\n     location: Bakersfield, CA\n     brand_color: \"#f9c65d\"\n   \n   api_limits:\n     max_retries: 3\n     retry_backoff: 2\n     cache_duration_hours: 24\n   ```\n\n6. Initialize Git repository with .gitignore:\n   - Ignore .env, venv/, __pycache__/, output/, logs/\n\n7. Create README.md with quick start guide",
        "testStrategy": "1. Verify virtual environment activates successfully\n2. Install all dependencies without errors\n3. Validate .env.example contains all required keys\n4. Parse config.yaml successfully with PyYAML\n5. Verify .gitignore excludes sensitive files\n6. Run `python --version` to confirm Python 3.11+",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Universal Input Processing Module",
        "description": "Implement input detection and processing for 4 input types: YouTube URLs, Answer the Public questions, general topics, and competitor URLs",
        "details": "1. Create base input handler abstract class:\n   ```python\n   from abc import ABC, abstractmethod\n   from pydantic import BaseModel\n   \n   class NormalizedResearchData(BaseModel):\n       input_type: str\n       primary_topic: str\n       keywords: list[str]\n       source_url: str | None\n       raw_content: str | None\n       metadata: dict\n   \n   class BaseInputHandler(ABC):\n       @abstractmethod\n       def can_handle(self, input_text: str) -> bool:\n           pass\n       \n       @abstractmethod\n       def process(self, input_text: str) -> NormalizedResearchData:\n           pass\n   ```\n\n2. Implement YouTubeInputHandler:\n   - Regex to extract video ID from various URL formats\n   - Use youtube-transcript-api to fetch transcript\n   - Use YouTube Data API v3 to fetch metadata (title, description, channel, views)\n   - Parse into NormalizedResearchData\n\n3. Implement ATPQuestionHandler:\n   - Detect question patterns (how to, what is, can i, why, when, where)\n   - Parse question structure and extract keywords\n   - Determine schema type from question type\n   - Set input_type='atp'\n\n4. Implement GeneralTopicHandler:\n   - Clean and normalize topic text\n   - Extract core keywords using simple NLP (split, clean)\n   - Set input_type='topic'\n\n5. Implement CompetitorURLHandler:\n   - Use Jina Reader API to convert URL to markdown\n   - Extract title, headings, and main content\n   - Parse structure and keywords\n   - Set input_type='competitor'\n\n6. Create InputProcessor orchestrator:\n   ```python\n   class InputProcessor:\n       def __init__(self):\n           self.handlers = [\n               YouTubeInputHandler(),\n               CompetitorURLHandler(),\n               ATPQuestionHandler(),\n               GeneralTopicHandler()  # Fallback\n           ]\n       \n       def process(self, input_text: str, manual_type: str = None) -> NormalizedResearchData:\n           if manual_type:\n               handler = self._get_handler_by_type(manual_type)\n               return handler.process(input_text)\n           \n           for handler in self.handlers:\n               if handler.can_handle(input_text):\n                   return handler.process(input_text)\n           \n           raise ValueError(\"Unable to detect input type\")\n   ```\n\n7. Add error handling for invalid URLs, API failures, and malformed inputs",
        "testStrategy": "1. Unit test each handler with sample inputs:\n   - YouTube: https://youtube.com/watch?v=ABC123\n   - ATP: \"how to remove late payments from credit report\"\n   - Topic: \"credit card rewards strategies\"\n   - Competitor: https://nerdwallet.com/article/credit\n2. Test auto-detection accuracy with 20 diverse inputs\n3. Verify NormalizedResearchData contains all required fields\n4. Test error handling for invalid YouTube URLs\n5. Test Jina Reader API integration with real competitor URL\n6. Verify manual type override works correctly",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "DataForSEO Keyword Research Integration",
        "description": "Integrate DataForSEO Keywords Data API for search volume, keyword difficulty, and related keyword extraction",
        "details": "1. Create DataForSEOClient class:\n   ```python\n   import requests\n   from requests.auth import HTTPBasicAuth\n   import os\n   from typing import Dict, List\n   \n   class DataForSEOClient:\n       BASE_URL = \"https://api.dataforseo.com/v3\"\n       \n       def __init__(self):\n           self.login = os.getenv('DATAFORSEO_LOGIN')\n           self.password = os.getenv('DATAFORSEO_PASSWORD')\n           self.auth = HTTPBasicAuth(self.login, self.password)\n       \n       def get_search_volume(self, keywords: List[str], location: str = \"United States\") -> Dict:\n           endpoint = f\"{self.BASE_URL}/keywords_data/google_ads/search_volume/live\"\n           payload = [{\n               \"keywords\": keywords,\n               \"location_name\": location,\n               \"language_name\": \"English\"\n           }]\n           response = requests.post(endpoint, json=payload, auth=self.auth)\n           response.raise_for_status()\n           return response.json()\n       \n       def get_related_keywords(self, keyword: str, location: str = \"United States\") -> Dict:\n           endpoint = f\"{self.BASE_URL}/keywords_data/google_ads/keywords_for_keywords/live\"\n           payload = [{\n               \"keywords\": [keyword],\n               \"location_name\": location,\n               \"language_name\": \"English\",\n               \"include_seed_keyword\": True,\n               \"sort_by\": \"search_volume\"\n           }]\n           response = requests.post(endpoint, json=payload, auth=self.auth)\n           response.raise_for_status()\n           return response.json()\n   ```\n\n2. Implement caching layer (24-hour cache):\n   - Use simple JSON file cache or SQLite\n   - Cache key: hash of (keyword, location)\n   - Check cache before API call\n   - Store timestamp with cached data\n\n3. Parse API responses:\n   - Extract search volume, competition level, CPC\n   - Calculate keyword difficulty score\n   - Filter and rank related keywords by volume and competition\n\n4. Implement retry logic with exponential backoff:\n   - Max 3 retries\n   - Backoff: 2^attempt seconds\n   - Handle rate limiting (429 status)\n\n5. Cost tracking:\n   - Track API calls and estimated cost\n   - Log to cost tracking database\n\n6. Create KeywordData model:\n   ```python\n   class KeywordData(BaseModel):\n       keyword: str\n       search_volume: int\n       competition: str  # LOW, MEDIUM, HIGH\n       cpc: float\n       difficulty: int  # 0-100\n   ```",
        "testStrategy": "1. Test API authentication with valid credentials\n2. Test search volume lookup for single keyword\n3. Test related keywords extraction (verify returns 10+ keywords)\n4. Test caching: second call should not hit API\n5. Test retry logic with mock 429 response\n6. Verify cost tracking logs API calls\n7. Test with Mesa Group relevant keywords: \"credit repair\", \"debt relief\"\n8. Validate response parsing handles all fields correctly",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Pytrends Google Trends Integration",
        "description": "Integrate Pytrends library for trending keyword analysis, interest over time, and rising queries",
        "details": "1. Create PytrendsClient class:\n   ```python\n   from pytrends.request import TrendReq\n   import pandas as pd\n   from typing import Dict, List\n   \n   class PytrendsClient:\n       def __init__(self):\n           self.pytrends = TrendReq(hl='en-US', tz=360)\n       \n       def get_interest_over_time(self, keyword: str, timeframe: str = 'today 12-m') -> pd.DataFrame:\n           self.pytrends.build_payload([keyword], timeframe=timeframe, geo='US')\n           return self.pytrends.interest_over_time()\n       \n       def get_related_queries(self, keyword: str) -> Dict:\n           self.pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n           return self.pytrends.related_queries()\n       \n       def get_trending_searches(self, country: str = 'united_states') -> pd.DataFrame:\n           return self.pytrends.trending_searches(pn=country)\n       \n       def analyze_trend_direction(self, keyword: str) -> str:\n           \"\"\"Determine if keyword is growing, declining, or stable\"\"\"\n           interest_df = self.get_interest_over_time(keyword)\n           if interest_df.empty:\n               return 'stable'\n           \n           # Compare first 3 months vs last 3 months\n           first_quarter = interest_df[keyword].iloc[:13].mean()\n           last_quarter = interest_df[keyword].iloc[-13:].mean()\n           \n           if last_quarter > first_quarter * 1.2:\n               return 'growing'\n           elif last_quarter < first_quarter * 0.8:\n               return 'declining'\n           else:\n               return 'stable'\n   ```\n\n2. Implement geographic breakdown:\n   - Get interest by region (US states)\n   - Focus on Bakersfield, CA if available\n   - Identify regional opportunities\n\n3. Extract rising queries:\n   - Parse related_queries() response\n   - Separate 'rising' and 'top' queries\n   - Filter for relevant queries (>50% relevance)\n\n4. Create TrendData model:\n   ```python\n   class TrendData(BaseModel):\n       keyword: str\n       trend_direction: str  # growing, declining, stable\n       current_interest: int  # 0-100\n       rising_queries: List[str]\n       top_queries: List[str]\n       regional_interest: Dict[str, int]\n   ```\n\n5. Combine with DataForSEO data:\n   - Merge search volume with trend data\n   - Identify easy-win keywords (high volume, growing trend, low competition)\n\n6. Error handling:\n   - Handle rate limiting (Pytrends has built-in delays)\n   - Graceful fallback if trends unavailable",
        "testStrategy": "1. Test interest over time for \"credit repair\" (12-month data)\n2. Test related queries extraction (verify rising and top queries)\n3. Test trending searches for US\n4. Test trend direction analysis (growing/declining/stable)\n5. Verify geographic breakdown returns state-level data\n6. Test with low-volume keyword (should handle gracefully)\n7. Test rate limiting doesn't cause failures\n8. Validate TrendData model with real API response",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Keyword Analysis and Synthesis Engine",
        "description": "Combine DataForSEO and Pytrends data to generate comprehensive keyword strategy with H2 suggestions, long-tail keywords, and AEO/GEO optimization data",
        "details": "1. Create KeywordAnalyzer class:\n   ```python\n   class KeywordAnalyzer:\n       def __init__(self, dataforseo_client: DataForSEOClient, pytrends_client: PytrendsClient):\n           self.dataforseo = dataforseo_client\n           self.pytrends = pytrends_client\n       \n       def analyze(self, primary_keyword: str) -> KeywordStrategy:\n           # Get DataForSEO data\n           search_data = self.dataforseo.get_search_volume([primary_keyword])\n           related_keywords = self.dataforseo.get_related_keywords(primary_keyword)\n           \n           # Get Pytrends data\n           trend_data = self.pytrends.analyze_trend_direction(primary_keyword)\n           related_queries = self.pytrends.get_related_queries(primary_keyword)\n           \n           # Synthesize\n           return self._synthesize_strategy(search_data, related_keywords, trend_data, related_queries)\n   ```\n\n2. Implement H2 header suggestion extraction:\n   - Filter related keywords for question patterns\n   - Prioritize \"how to\", \"what is\", \"can i\", \"why\", \"when\"\n   - Select 5-7 question-based keywords\n   - Format as natural language questions\n\n3. Implement long-tail keyword identification:\n   - Filter keywords with 4+ words\n   - Prioritize high volume, low competition\n   - Select 10 best long-tail opportunities\n\n4. Implement easy-win keyword selection:\n   - Score keywords: (search_volume / competition_score)\n   - Filter for growing trends\n   - Select top 10 easy-win keywords\n\n5. Determine schema type from keyword:\n   ```python\n   def determine_schema_type(self, keyword: str) -> str:\n       keyword_lower = keyword.lower()\n       if any(x in keyword_lower for x in ['how to', 'how do', 'steps to']):\n           return 'HowTo'\n       elif any(x in keyword_lower for x in ['what is', 'what are', 'define']):\n           return 'DefinedTerm'\n       elif '?' in keyword or any(x in keyword_lower for x in ['can i', 'should i', 'why']):\n           return 'FAQPage'\n       else:\n           return 'Article'\n   ```\n\n6. Create KeywordStrategy model:\n   ```python\n   class KeywordStrategy(BaseModel):\n       primary_keyword: KeywordData\n       target_keywords: List[KeywordData]  # 10-20 keywords\n       h2_suggestions: List[str]  # 5-7 question-based\n       long_tail_keywords: List[KeywordData]  # 10 keywords\n       easy_win_keywords: List[KeywordData]  # 10 keywords\n       rising_queries: List[str]\n       trend_direction: str\n       recommended_schema: str\n       aeo_geo_keywords: List[str]  # Quotable, standalone phrases\n   ```\n\n7. Generate AEO/GEO optimization keywords:\n   - Extract quotable phrases\n   - Identify entity relationships\n   - Create semantic keyword clusters",
        "testStrategy": "1. Test with \"how to remove late payments from credit report\":\n   - Verify schema type = HowTo\n   - Verify 5+ H2 suggestions are questions\n   - Verify 10+ long-tail keywords extracted\n2. Test with \"what is FCRA\":\n   - Verify schema type = DefinedTerm\n3. Test keyword scoring algorithm (easy-win selection)\n4. Verify target keywords list contains 10-20 items\n5. Test with low-volume keyword (graceful handling)\n6. Validate KeywordStrategy model completeness\n7. Test caching: second analysis should be faster",
        "priority": "high",
        "dependencies": [
          3,
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Perplexity Multi-Source Research Integration",
        "description": "Integrate Perplexity API to research topic from multiple authoritative sources and extract citations",
        "details": "1. Create PerplexityResearcher class:\n   ```python\n   import requests\n   import os\n   from typing import List, Dict\n   \n   class PerplexityResearcher:\n       API_URL = \"https://api.perplexity.ai/chat/completions\"\n       \n       def __init__(self):\n           self.api_key = os.getenv('PERPLEXITY_API_KEY')\n       \n       def research_topic(self, topic: str, focus_areas: List[str] = None) -> Dict:\n           prompt = self._build_research_prompt(topic, focus_areas)\n           \n           payload = {\n               \"model\": \"llama-3.1-sonar-large-128k-online\",\n               \"messages\": [\n                   {\"role\": \"system\", \"content\": \"You are a research assistant. Provide comprehensive information with authoritative citations.\"},\n                   {\"role\": \"user\", \"content\": prompt}\n               ],\n               \"temperature\": 0.2,\n               \"return_citations\": True,\n               \"return_images\": False\n           }\n           \n           headers = {\n               \"Authorization\": f\"Bearer {self.api_key}\",\n               \"Content-Type\": \"application/json\"\n           }\n           \n           response = requests.post(self.API_URL, json=payload, headers=headers)\n           response.raise_for_status()\n           return response.json()\n       \n       def _build_research_prompt(self, topic: str, focus_areas: List[str] = None) -> str:\n           prompt = f\"Research the topic: {topic}\\n\\n\"\n           prompt += \"Provide:\\n\"\n           prompt += \"1. Top 10 authoritative articles and sources\\n\"\n           prompt += \"2. Key insights and main points\\n\"\n           prompt += \"3. Government regulations and official sources (CFPB, FTC, credit bureaus)\\n\"\n           prompt += \"4. Statistics and data points with sources\\n\"\n           prompt += \"5. Common questions and answers\\n\"\n           \n           if focus_areas:\n               prompt += f\"\\nFocus on these areas: {', '.join(focus_areas)}\\n\"\n           \n           return prompt\n   ```\n\n2. Parse Perplexity response:\n   - Extract main content\n   - Parse citations array\n   - Identify authoritative sources (government, bureaus, regulations)\n   - Extract key points and insights\n\n3. Implement source quality scoring:\n   ```python\n   def score_source_quality(self, url: str) -> int:\n       \"\"\"Score 0-100 based on source authority\"\"\"\n       domain = self._extract_domain(url)\n       \n       # Government sources (highest authority)\n       if any(x in domain for x in ['.gov', 'cfpb.gov', 'ftc.gov', 'consumerfinance.gov']):\n           return 100\n       \n       # Credit bureaus and financial institutions\n       if any(x in domain for x in ['equifax.com', 'experian.com', 'transunion.com']):\n           return 90\n       \n       # Established financial sites\n       if any(x in domain for x in ['nerdwallet.com', 'creditkarma.com', 'bankrate.com']):\n           return 70\n       \n       # General news and blogs\n       return 50\n   ```\n\n4. Create ResearchData model:\n   ```python\n   class Citation(BaseModel):\n       url: str\n       title: str\n       quality_score: int\n       excerpt: str\n   \n   class ResearchData(BaseModel):\n       topic: str\n       main_insights: List[str]\n       key_points: List[str]\n       citations: List[Citation]\n       authoritative_sources: List[Citation]  # Filtered for quality_score >= 80\n       statistics: List[Dict[str, str]]  # stat + source\n       common_questions: List[str]\n   ```\n\n5. Implement timeout and retry logic:\n   - Max 2 minutes for research\n   - Retry on transient failures\n   - Graceful degradation if API fails",
        "testStrategy": "1. Test research for \"credit repair\" topic\n2. Verify returns 10+ sources\n3. Verify at least 3 authoritative citations (quality_score >= 80)\n4. Test citation extraction and parsing\n5. Test source quality scoring algorithm\n6. Verify key points and insights are extracted\n7. Test timeout handling (mock slow response)\n8. Test with Mesa Group specific topics (FCRA, FDCPA, credit disputes)\n9. Validate ResearchData model completeness",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "YouTube Search and Transcript Extraction",
        "description": "Implement YouTube Data API search and transcript extraction for multi-source video research",
        "details": "1. Create YouTubeSearcher class:\n   ```python\n   from googleapiclient.discovery import build\n   from youtube_transcript_api import YouTubeTranscriptApi\n   import os\n   from typing import List, Dict\n   \n   class YouTubeSearcher:\n       def __init__(self):\n           self.api_key = os.getenv('YOUTUBE_API_KEY')\n           self.youtube = build('youtube', 'v3', developerKey=self.api_key)\n       \n       def search_videos(self, query: str, max_results: int = 5) -> List[Dict]:\n           request = self.youtube.search().list(\n               q=query,\n               part='id,snippet',\n               type='video',\n               maxResults=max_results,\n               order='relevance',\n               relevanceLanguage='en',\n               safeSearch='moderate'\n           )\n           response = request.execute()\n           \n           videos = []\n           for item in response['items']:\n               video_id = item['id']['videoId']\n               video_details = self._get_video_details(video_id)\n               videos.append(video_details)\n           \n           # Sort by view count and engagement\n           videos.sort(key=lambda x: x['view_count'], reverse=True)\n           return videos[:max_results]\n       \n       def _get_video_details(self, video_id: str) -> Dict:\n           request = self.youtube.videos().list(\n               part='snippet,statistics',\n               id=video_id\n           )\n           response = request.execute()\n           \n           if not response['items']:\n               return None\n           \n           item = response['items'][0]\n           return {\n               'video_id': video_id,\n               'title': item['snippet']['title'],\n               'description': item['snippet']['description'],\n               'channel': item['snippet']['channelTitle'],\n               'view_count': int(item['statistics'].get('viewCount', 0)),\n               'like_count': int(item['statistics'].get('likeCount', 0)),\n               'comment_count': int(item['statistics'].get('commentCount', 0))\n           }\n   ```\n\n2. Create TranscriptExtractor class:\n   ```python\n   class TranscriptExtractor:\n       def extract_transcript(self, video_id: str) -> str:\n           try:\n               transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n               transcript_text = ' '.join([entry['text'] for entry in transcript_list])\n               return transcript_text\n           except Exception as e:\n               # Handle videos without transcripts\n               return None\n       \n       def extract_multiple_transcripts(self, video_ids: List[str]) -> Dict[str, str]:\n           transcripts = {}\n           for video_id in video_ids:\n               transcript = self.extract_transcript(video_id)\n               if transcript:\n                   transcripts[video_id] = transcript\n           return transcripts\n   ```\n\n3. Implement video filtering:\n   - Filter by minimum view count (10k+)\n   - Filter by recency (last 2 years preferred)\n   - Filter by engagement rate (likes/views ratio)\n   - Select top 3-5 videos\n\n4. Create VideoResearchData model:\n   ```python\n   class VideoData(BaseModel):\n       video_id: str\n       title: str\n       channel: str\n       view_count: int\n       transcript: str\n       url: str\n   \n   class VideoResearchData(BaseModel):\n       query: str\n       videos: List[VideoData]\n       combined_transcript: str\n       key_concepts: List[str]\n   ```\n\n5. Implement parallel transcript extraction:\n   - Use ThreadPoolExecutor for concurrent extraction\n   - Timeout per video (30 seconds)\n   - Combine transcripts for comprehensive coverage\n\n6. Extract key concepts from transcripts:\n   - Identify frequently mentioned terms\n   - Extract advice and recommendations\n   - Parse for actionable steps",
        "testStrategy": "1. Test YouTube search for \"credit repair tips\"\n2. Verify returns 3-5 relevant videos\n3. Test video filtering (view count, engagement)\n4. Test transcript extraction for single video\n5. Test multiple transcript extraction (3 videos)\n6. Verify combined transcript is coherent\n7. Test error handling for videos without transcripts\n8. Test quota management (YouTube API has daily limits)\n9. Validate VideoResearchData model completeness",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Competitor URL Analysis with Jina Reader",
        "description": "Implement competitor content scraping and analysis using Jina Reader API to identify content gaps and improvement opportunities",
        "details": "1. Create CompetitorAnalyzer class:\n   ```python\n   import requests\n   import os\n   from typing import Dict, List\n   \n   class CompetitorAnalyzer:\n       JINA_API_URL = \"https://r.jina.ai\"\n       \n       def __init__(self):\n           self.api_key = os.getenv('JINA_API_KEY', '')\n       \n       def scrape_url(self, url: str) -> str:\n           \"\"\"Convert URL to clean markdown using Jina Reader\"\"\"\n           headers = {}\n           if self.api_key:\n               headers['Authorization'] = f'Bearer {self.api_key}'\n           \n           jina_url = f\"{self.JINA_API_URL}/{url}\"\n           response = requests.get(jina_url, headers=headers)\n           response.raise_for_status()\n           return response.text\n       \n       def analyze_competitor(self, url: str) -> Dict:\n           markdown_content = self.scrape_url(url)\n           \n           analysis = {\n               'url': url,\n               'content': markdown_content,\n               'structure': self._analyze_structure(markdown_content),\n               'keywords': self._extract_keywords(markdown_content),\n               'strengths': self._identify_strengths(markdown_content),\n               'weaknesses': self._identify_weaknesses(markdown_content),\n               'gaps': self._identify_gaps(markdown_content),\n               'citations': self._extract_citations(markdown_content)\n           }\n           \n           return analysis\n       \n       def _analyze_structure(self, content: str) -> Dict:\n           \"\"\"Analyze content structure (headings, lists, tables)\"\"\"\n           lines = content.split('\\n')\n           \n           structure = {\n               'h1_count': len([l for l in lines if l.startswith('# ')]),\n               'h2_count': len([l for l in lines if l.startswith('## ')]),\n               'h3_count': len([l for l in lines if l.startswith('### ')]),\n               'list_count': len([l for l in lines if l.strip().startswith(('-', '*', '1.'))]),\n               'word_count': len(content.split()),\n               'has_tables': '|' in content\n           }\n           \n           return structure\n       \n       def _extract_keywords(self, content: str) -> List[str]:\n           \"\"\"Extract prominent keywords from content\"\"\"\n           # Simple keyword extraction (can be enhanced with NLP)\n           words = content.lower().split()\n           # Filter common words and extract 2-3 word phrases\n           # Return top 20 keywords\n           return []  # Placeholder for actual implementation\n       \n       def _identify_strengths(self, content: str) -> List[str]:\n           \"\"\"Identify what the competitor does well\"\"\"\n           strengths = []\n           \n           structure = self._analyze_structure(content)\n           \n           if structure['word_count'] > 2000:\n               strengths.append('Comprehensive coverage (2000+ words)')\n           \n           if structure['list_count'] > 5:\n               strengths.append('Good use of lists for readability')\n           \n           if structure['has_tables']:\n               strengths.append('Includes comparison tables')\n           \n           if structure['h2_count'] >= 5:\n               strengths.append('Well-structured with clear sections')\n           \n           return strengths\n       \n       def _identify_weaknesses(self, content: str) -> List[str]:\n           \"\"\"Identify areas where competitor content is lacking\"\"\"\n           weaknesses = []\n           \n           structure = self._analyze_structure(content)\n           \n           if structure['word_count'] < 1000:\n               weaknesses.append('Thin content (<1000 words)')\n           \n           if structure['h2_count'] < 3:\n               weaknesses.append('Poor structure (few headings)')\n           \n           # Check for AEO/GEO optimization\n           if '?' not in content[:500]:  # No question in intro\n               weaknesses.append('No direct answer in introduction')\n           \n           return weaknesses\n       \n       def _identify_gaps(self, content: str) -> List[str]:\n           \"\"\"Identify topics not covered by competitor\"\"\"\n           # Placeholder - would compare against comprehensive topic list\n           return ['Opportunity to add more authoritative citations', 'Could include more actionable steps']\n       \n       def _extract_citations(self, content: str) -> List[str]:\n           \"\"\"Extract URLs and citations from content\"\"\"\n           import re\n           urls = re.findall(r'https?://[^\\s)]+', content)\n           return urls\n   ```\n\n2. Create CompetitorAnalysis model:\n   ```python\n   class CompetitorAnalysis(BaseModel):\n       url: str\n       word_count: int\n       structure: Dict\n       keywords: List[str]\n       strengths: List[str]\n       weaknesses: List[str]\n       gaps: List[str]\n       citations: List[str]\n       improvement_strategy: str\n   ```\n\n3. Generate improvement strategy:\n   - Combine strengths to match\n   - Address weaknesses\n   - Fill content gaps\n   - Add superior AEO/GEO optimization",
        "testStrategy": "1. Test Jina Reader API with competitor URL (e.g., NerdWallet article)\n2. Verify markdown conversion is clean and readable\n3. Test structure analysis (heading counts, word count)\n4. Test keyword extraction\n5. Verify strengths and weaknesses identification\n6. Test citation extraction\n7. Test with various competitor sites (NerdWallet, Credit Karma, Bankrate)\n8. Validate CompetitorAnalysis model completeness\n9. Test error handling for invalid URLs or blocked sites",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Research Synthesis and Content Planning Engine",
        "description": "Aggregate and synthesize research from all sources (Perplexity, YouTube, competitor) to create comprehensive content outline and unique angle",
        "details": "1. Create SourceAggregator class:\n   ```python\n   class SourceAggregator:\n       def aggregate(\n           self,\n           keyword_strategy: KeywordStrategy,\n           perplexity_research: ResearchData,\n           youtube_research: VideoResearchData,\n           competitor_analysis: CompetitorAnalysis = None\n       ) -> AggregatedResearch:\n           \n           # Combine all sources\n           all_citations = self._merge_citations(\n               perplexity_research.citations,\n               competitor_analysis.citations if competitor_analysis else []\n           )\n           \n           # Extract unique insights\n           unique_insights = self._identify_unique_insights(\n               perplexity_research.key_points,\n               youtube_research.key_concepts,\n               competitor_analysis.gaps if competitor_analysis else []\n           )\n           \n           # Determine content angle\n           content_angle = self._determine_content_angle(\n               keyword_strategy,\n               competitor_analysis\n           )\n           \n           return AggregatedResearch(\n               topic=keyword_strategy.primary_keyword.keyword,\n               all_sources=all_citations,\n               authoritative_citations=self._filter_authoritative(all_citations),\n               key_insights=unique_insights,\n               content_angle=content_angle,\n               outline=self._generate_outline(keyword_strategy, unique_insights)\n           )\n   ```\n\n2. Implement citation merging and deduplication:\n   - Combine citations from all sources\n   - Remove duplicates (same domain)\n   - Prioritize authoritative sources\n   - Ensure minimum 5 authoritative citations\n\n3. Implement unique angle identification:\n   ```python\n   def _determine_content_angle(self, keyword_strategy: KeywordStrategy, competitor_analysis: CompetitorAnalysis = None) -> str:\n       \"\"\"Determine unique angle for content\"\"\"\n       \n       if competitor_analysis:\n           # Create superior version addressing gaps\n           gaps = competitor_analysis.gaps\n           return f\"Comprehensive guide addressing: {', '.join(gaps[:3])}\"\n       \n       # Determine angle from keyword type\n       if keyword_strategy.recommended_schema == 'HowTo':\n           return \"Step-by-step actionable guide with real examples\"\n       elif keyword_strategy.recommended_schema == 'DefinedTerm':\n           return \"Clear definition with practical applications\"\n       elif keyword_strategy.recommended_schema == 'FAQPage':\n           return \"Comprehensive Q&A addressing all common questions\"\n       else:\n           return \"In-depth analysis with expert insights\"\n   ```\n\n4. Generate content outline:\n   ```python\n   def _generate_outline(self, keyword_strategy: KeywordStrategy, insights: List[str]) -> ContentOutline:\n       \"\"\"Generate structured content outline\"\"\"\n       \n       outline = ContentOutline(\n           title=self._generate_title(keyword_strategy.primary_keyword),\n           introduction={\n               'hook': 'Attention-grabbing statistic or question',\n               'direct_answer': 'Answer main question in 150-200 words',\n               'preview': 'What this article covers'\n           },\n           sections=[],\n           conclusion={\n               'summary': 'Recap key points',\n               'cta': 'Call to action for Mesa Group services'\n           }\n       )\n       \n       # Create sections from H2 suggestions\n       for h2_question in keyword_strategy.h2_suggestions:\n           outline.sections.append({\n               'heading': h2_question,\n               'key_points': [],  # To be filled by content generator\n               'keywords': []  # Related keywords for this section\n           })\n       \n       return outline\n   ```\n\n5. Create AggregatedResearch model:\n   ```python\n   class ContentOutline(BaseModel):\n       title: str\n       introduction: Dict\n       sections: List[Dict]\n       conclusion: Dict\n   \n   class AggregatedResearch(BaseModel):\n       topic: str\n       all_sources: List[Citation]\n       authoritative_citations: List[Citation]\n       key_insights: List[str]\n       content_angle: str\n       outline: ContentOutline\n       target_audience: str\n       mesa_group_relevance: str\n   ```",
        "testStrategy": "1. Test aggregation with all research sources\n2. Verify citation deduplication works\n3. Verify minimum 5 authoritative citations\n4. Test unique angle determination for different schema types\n5. Test outline generation with H2 suggestions\n6. Verify outline has introduction, 5+ sections, conclusion\n7. Test with competitor analysis (improvement strategy)\n8. Test without competitor analysis (original angle)\n9. Validate AggregatedResearch model completeness",
        "priority": "high",
        "dependencies": [
          5,
          6,
          7,
          8
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "AEO/GEO Optimized Content Generation with Gemini",
        "description": "Generate blog post, YouTube script, metadata, and schema markup using Google Gemini API with AEO/GEO optimization prompts",
        "details": "1. Create ContentGenerator class:\n   ```python\n   import google.generativeai as genai\n   import os\n   import json\n   \n   class ContentGenerator:\n       def __init__(self):\n           genai.configure(api_key=os.getenv('GEMINI_API_KEY'))\n           self.model = genai.GenerativeModel('gemini-1.5-pro-latest')\n       \n       def generate_all_content(\n           self,\n           aggregated_research: AggregatedResearch,\n           keyword_strategy: KeywordStrategy\n       ) -> GeneratedContent:\n           \n           prompt = self._build_comprehensive_prompt(\n               aggregated_research,\n               keyword_strategy\n           )\n           \n           response = self.model.generate_content(\n               prompt,\n               generation_config=genai.GenerationConfig(\n                   temperature=0.7,\n                   top_p=0.95,\n                   top_k=40,\n                   max_output_tokens=8192,\n               )\n           )\n           \n           # Parse structured JSON response\n           content_json = self._parse_json_response(response.text)\n           \n           return GeneratedContent(\n               blog_post_html=content_json['blog_post'],\n               youtube_script=content_json['youtube_script'],\n               youtube_metadata=content_json['youtube_metadata'],\n               schema_markup=content_json['schema_markup'],\n               image_prompts=content_json['image_prompts'],\n               meta_description=content_json['meta_description']\n           )\n   ```\n\n2. Build comprehensive generation prompt:\n   ```python\n   def _build_comprehensive_prompt(self, research: AggregatedResearch, keywords: KeywordStrategy) -> str:\n       prompt = f\"\"\"\n       You are an expert content creator for Mesa Group Consulting, a credit repair and debt relief company in Bakersfield, CA.\n       Author: Evert Calderon, credit repair expert.\n       \n       Generate a complete content package for the topic: {research.topic}\n       \n       RESEARCH DATA:\n       - Primary Keyword: {keywords.primary_keyword.keyword} (Volume: {keywords.primary_keyword.search_volume})\n       - Target Keywords: {', '.join([k.keyword for k in keywords.target_keywords[:10]])}\n       - H2 Suggestions: {', '.join(keywords.h2_suggestions)}\n       - Content Angle: {research.content_angle}\n       - Key Insights: {json.dumps(research.key_insights)}\n       - Authoritative Citations: {json.dumps([c.url for c in research.authoritative_citations])}\n       \n       GENERATE THE FOLLOWING (return as JSON):\n       \n       1. BLOG POST (HTML format, 1500-2500 words):\n          - Direct answer in first 150-200 words (for featured snippets)\n          - Use H2 headers from suggestions (question-based)\n          - Include bulleted and numbered lists\n          - Cite authoritative sources (CFPB, FTC, credit bureaus)\n          - Quotable, standalone statements (AEO/GEO optimized)\n          - Active voice, declarative sentences\n          - Include [IMAGE 1: description] placeholders\n          - Include [LINK: internal page] suggestions\n          - Author bio section for Evert Calderon\n          - CTA for Mesa Group services\n       \n       2. YOUTUBE SCRIPT (1750-2500 words, teleprompter-ready):\n          - Hook (first 30 seconds)\n          - Introduction (who you are, what video covers)\n          - Main content (5-8 minutes, keyword-rich but natural)\n          - 3 CTAs (at 3min, 6min, end)\n          - Outro (recap, subscribe)\n          - Include [B-ROLL: description] suggestions\n          - Include [00:30], [03:00] timestamp markers\n          - Include [PAUSE] and [EMPHASIZE: text] markers\n       \n       3. YOUTUBE METADATA:\n          - Title (60-70 chars, primary keyword)\n          - Description (200-300 words, keyword-rich first 150 chars, timestamps, links)\n          - Tags (15-20 tags)\n          - Category\n          - Thumbnail suggestions\n       \n       4. SCHEMA MARKUP (JSON-LD):\n          - Type: {keywords.recommended_schema}\n          - Include all required fields\n          - Author: Evert Calderon, Mesa Group Consulting\n       \n       5. IMAGE PROMPTS (2-3 prompts):\n          - Format: \"Blog Post: [topic], Image [number], [description]\"\n          - Style: Modern, clean, financial services aesthetic\n          - Colors: Mesa Group gold (#f9c65d), dark gray, white\n       \n       6. META DESCRIPTION (150 chars, keyword-rich)\n       \n       AEO/GEO REQUIREMENTS:\n       - First 200 words answer the main question directly\n       - Minimum 3 question-based H2 headers\n       - At least 2 bulleted or numbered lists\n       - Minimum 5 authoritative citations\n       - Active voice >80%\n       - Zero marketing fluff in factual sections\n       - Answer related questions inline\n       \n       Return ONLY valid JSON with keys: blog_post, youtube_script, youtube_metadata, schema_markup, image_prompts, meta_description\n       \"\"\"\n       return prompt\n   ```\n\n3. Implement JSON response parsing:\n   - Extract JSON from markdown code blocks\n   - Validate all required fields present\n   - Handle malformed JSON gracefully\n\n4. Create GeneratedContent model:\n   ```python\n   class GeneratedContent(BaseModel):\n       blog_post_html: str\n       youtube_script: str\n       youtube_metadata: Dict\n       schema_markup: Dict\n       image_prompts: List[str]\n       meta_description: str\n   ```\n\n5. Implement retry logic for generation failures:\n   - Retry up to 2 times with adjusted prompt\n   - Track token usage and cost",
        "testStrategy": "1. Test content generation with sample research data\n2. Verify blog post is 1500-2500 words\n3. Verify YouTube script is 1750-2500 words\n4. Verify JSON response parsing works\n5. Test AEO/GEO compliance:\n   - Direct answer in first 200 words\n   - Question-based H2 headers\n   - Lists present\n   - Citations included\n6. Verify schema markup is valid JSON-LD\n7. Test image prompts format\n8. Verify meta description is 150 chars\n9. Test with different schema types (HowTo, FAQPage, Article)\n10. Validate GeneratedContent model completeness",
        "priority": "high",
        "dependencies": [
          9
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Schema Markup Auto-Generation and Validation",
        "description": "Implement automatic schema.org JSON-LD generation for HowTo, FAQPage, Article, and DefinedTerm schemas with validation",
        "details": "1. Create SchemaGenerator class:\n   ```python\n   from datetime import datetime\n   import json\n   \n   class SchemaGenerator:\n       def generate_schema(\n           self,\n           schema_type: str,\n           content: GeneratedContent,\n           keyword_strategy: KeywordStrategy,\n           research: AggregatedResearch\n       ) -> Dict:\n           \n           if schema_type == 'HowTo':\n               return self._generate_howto_schema(content, keyword_strategy)\n           elif schema_type == 'FAQPage':\n               return self._generate_faq_schema(content, keyword_strategy)\n           elif schema_type == 'DefinedTerm':\n               return self._generate_defined_term_schema(content, keyword_strategy)\n           else:\n               return self._generate_article_schema(content, keyword_strategy)\n       \n       def _generate_howto_schema(self, content: GeneratedContent, keywords: KeywordStrategy) -> Dict:\n           # Parse steps from blog post content\n           steps = self._extract_steps_from_content(content.blog_post_html)\n           \n           schema = {\n               \"@context\": \"https://schema.org\",\n               \"@type\": \"HowTo\",\n               \"name\": keywords.primary_keyword.keyword,\n               \"description\": content.meta_description,\n               \"step\": steps,\n               \"totalTime\": \"PT30M\",  # Estimate based on content\n               \"author\": {\n                   \"@type\": \"Person\",\n                   \"name\": \"Evert Calderon\",\n                   \"jobTitle\": \"Credit Repair Expert\",\n                   \"affiliation\": {\n                       \"@type\": \"Organization\",\n                       \"name\": \"Mesa Group Consulting\",\n                       \"address\": {\n                           \"@type\": \"PostalAddress\",\n                           \"addressLocality\": \"Bakersfield\",\n                           \"addressRegion\": \"CA\"\n                       }\n                   }\n               },\n               \"datePublished\": datetime.now().isoformat(),\n               \"dateModified\": datetime.now().isoformat()\n           }\n           return schema\n       \n       def _generate_faq_schema(self, content: GeneratedContent, keywords: KeywordStrategy) -> Dict:\n           # Parse Q&A pairs from content\n           qa_pairs = self._extract_qa_pairs(content.blog_post_html)\n           \n           schema = {\n               \"@context\": \"https://schema.org\",\n               \"@type\": \"FAQPage\",\n               \"mainEntity\": qa_pairs,\n               \"author\": self._get_author_schema(),\n               \"datePublished\": datetime.now().isoformat()\n           }\n           return schema\n       \n       def _generate_article_schema(self, content: GeneratedContent, keywords: KeywordStrategy) -> Dict:\n           schema = {\n               \"@context\": \"https://schema.org\",\n               \"@type\": \"Article\",\n               \"headline\": keywords.primary_keyword.keyword,\n               \"description\": content.meta_description,\n               \"author\": self._get_author_schema(),\n               \"publisher\": {\n                   \"@type\": \"Organization\",\n                   \"name\": \"Mesa Group Consulting\",\n                   \"logo\": {\n                       \"@type\": \"ImageObject\",\n                       \"url\": \"https://blog.mesagroupconsulting.com/logo.png\"\n                   }\n               },\n               \"datePublished\": datetime.now().isoformat(),\n               \"dateModified\": datetime.now().isoformat(),\n               \"wordCount\": len(content.blog_post_html.split()),\n               \"keywords\": ', '.join([k.keyword for k in keywords.target_keywords[:10]])\n           }\n           return schema\n       \n       def _generate_defined_term_schema(self, content: GeneratedContent, keywords: KeywordStrategy) -> Dict:\n           schema = {\n               \"@context\": \"https://schema.org\",\n               \"@type\": \"DefinedTerm\",\n               \"name\": keywords.primary_keyword.keyword,\n               \"description\": content.meta_description,\n               \"inDefinedTermSet\": \"Credit Repair and Financial Services Terminology\",\n               \"author\": self._get_author_schema()\n           }\n           return schema\n       \n       def _get_author_schema(self) -> Dict:\n           return {\n               \"@type\": \"Person\",\n               \"name\": \"Evert Calderon\",\n               \"jobTitle\": \"Credit Repair Expert\",\n               \"affiliation\": {\n                   \"@type\": \"Organization\",\n                   \"name\": \"Mesa Group Consulting\"\n               }\n           }\n   ```\n\n2. Implement schema validation:\n   ```python\n   def validate_schema(self, schema: Dict) -> bool:\n       \"\"\"Validate schema has required fields\"\"\"\n       required_fields = ['@context', '@type']\n       \n       for field in required_fields:\n           if field not in schema:\n               return False\n       \n       # Type-specific validation\n       schema_type = schema['@type']\n       \n       if schema_type == 'HowTo':\n           return 'step' in schema and len(schema['step']) > 0\n       elif schema_type == 'FAQPage':\n           return 'mainEntity' in schema and len(schema['mainEntity']) > 0\n       elif schema_type == 'Article':\n           return 'headline' in schema and 'author' in schema\n       elif schema_type == 'DefinedTerm':\n           return 'name' in schema and 'description' in schema\n       \n       return True\n   ```\n\n3. Implement content parsing helpers:\n   - Extract steps from numbered lists\n   - Extract Q&A pairs from H2/H3 questions\n   - Proper escaping of special characters",
        "testStrategy": "1. Test HowTo schema generation\n2. Test FAQPage schema generation\n3. Test Article schema generation\n4. Test DefinedTerm schema generation\n5. Validate all schemas at https://validator.schema.org\n6. Verify required fields present for each type\n7. Test JSON-LD format is valid\n8. Test special character escaping\n9. Verify author and organization data correct\n10. Test WordPress injection format",
        "priority": "high",
        "dependencies": [
          10
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Output File Management and Organization",
        "description": "Implement organized file structure for saving all generated content with proper naming and atomic writes",
        "details": "1. Create OutputHandler class:\n   ```python\n   import os\n   import json\n   from pathlib import Path\n   from datetime import datetime\n   import re\n   \n   class OutputHandler:\n       def __init__(self, base_output_dir: str = 'output'):\n           self.base_dir = Path(base_output_dir)\n           self.base_dir.mkdir(exist_ok=True)\n       \n       def save_content_package(\n           self,\n           topic: str,\n           generated_content: GeneratedContent,\n           keyword_strategy: KeywordStrategy,\n           research: AggregatedResearch,\n           schema: Dict,\n           input_type: str,\n           source_url: str = None\n       ) -> Path:\n           \n           # Create topic-specific directory\n           slug = self._create_slug(topic)\n           timestamp = datetime.now().strftime('%Y-%m-%d')\n           dir_name = f\"{timestamp}-{slug}\"\n           output_dir = self.base_dir / dir_name\n           output_dir.mkdir(exist_ok=True)\n           \n           # Save all files\n           files_saved = []\n           \n           # 1. Blog post HTML\n           blog_path = output_dir / 'blog-post.html'\n           self._atomic_write(blog_path, generated_content.blog_post_html)\n           files_saved.append(blog_path)\n           \n           # 2. YouTube script\n           script_path = output_dir / 'youtube-script.txt'\n           self._atomic_write(script_path, generated_content.youtube_script)\n           files_saved.append(script_path)\n           \n           # 3. YouTube metadata\n           metadata_path = output_dir / 'youtube-metadata.json'\n           self._atomic_write_json(metadata_path, generated_content.youtube_metadata)\n           files_saved.append(metadata_path)\n           \n           # 4. Schema markup\n           schema_path = output_dir / 'schema-markup.json'\n           self._atomic_write_json(schema_path, schema)\n           files_saved.append(schema_path)\n           \n           # 5. Image prompts\n           image_path = output_dir / 'image-prompts.txt'\n           self._atomic_write(image_path, '\\n\\n'.join(generated_content.image_prompts))\n           files_saved.append(image_path)\n           \n           # 6. SEO report\n           seo_report = self._create_seo_report(keyword_strategy, generated_content)\n           seo_path = output_dir / 'seo-report.json'\n           self._atomic_write_json(seo_path, seo_report)\n           files_saved.append(seo_path)\n           \n           # 7. Research sources\n           sources = {\n               'authoritative_citations': [c.dict() for c in research.authoritative_citations],\n               'all_sources': [c.dict() for c in research.all_sources]\n           }\n           sources_path = output_dir / 'research-sources.json'\n           self._atomic_write_json(sources_path, sources)\n           files_saved.append(sources_path)\n           \n           # 8. Metadata\n           metadata = {\n               'topic': topic,\n               'slug': slug,\n               'input_type': input_type,\n               'source_url': source_url,\n               'generation_timestamp': datetime.now().isoformat(),\n               'primary_keyword': keyword_strategy.primary_keyword.keyword,\n               'files_saved': [str(f) for f in files_saved]\n           }\n           metadata_path = output_dir / 'metadata.json'\n           self._atomic_write_json(metadata_path, metadata)\n           files_saved.append(metadata_path)\n           \n           return output_dir\n       \n       def _create_slug(self, topic: str) -> str:\n           \"\"\"Create URL-safe slug from topic\"\"\"\n           slug = topic.lower()\n           slug = re.sub(r'[^a-z0-9]+', '-', slug)\n           slug = slug.strip('-')\n           slug = slug[:50]  # Max 50 characters\n           return slug\n       \n       def _atomic_write(self, path: Path, content: str):\n           \"\"\"Write file atomically to prevent partial writes\"\"\"\n           temp_path = path.with_suffix('.tmp')\n           try:\n               with open(temp_path, 'w', encoding='utf-8') as f:\n                   f.write(content)\n               temp_path.replace(path)\n           except Exception as e:\n               if temp_path.exists():\n                   temp_path.unlink()\n               raise e\n       \n       def _atomic_write_json(self, path: Path, data: dict):\n           \"\"\"Write JSON file atomically\"\"\"\n           content = json.dumps(data, indent=2, ensure_ascii=False)\n           self._atomic_write(path, content)\n       \n       def _create_seo_report(self, keywords: KeywordStrategy, content: GeneratedContent) -> Dict:\n           return {\n               'primary_keyword': keywords.primary_keyword.dict(),\n               'target_keywords': [k.dict() for k in keywords.target_keywords],\n               'h2_suggestions': keywords.h2_suggestions,\n               'long_tail_keywords': [k.dict() for k in keywords.long_tail_keywords],\n               'trend_direction': keywords.trend_direction,\n               'meta_description': content.meta_description,\n               'recommended_schema': keywords.recommended_schema\n           }\n   ```\n\n2. Implement file overwrite protection:\n   - Check if directory exists\n   - Prompt user before overwriting\n   - Option to append timestamp to avoid conflicts\n\n3. Implement backup functionality (optional):\n   - Keep previous version with .bak extension",
        "testStrategy": "1. Test directory creation with valid topic\n2. Test slug generation (special characters, length limit)\n3. Test all 8 files save successfully\n4. Test atomic write (simulate interruption)\n5. Test JSON files parse correctly after save\n6. Test file overwrite protection\n7. Verify filenames are valid across OS (Windows, Mac, Linux)\n8. Test with long topic names (>50 chars)\n9. Test with special characters in topic\n10. Verify metadata.json contains all required fields",
        "priority": "medium",
        "dependencies": [
          10,
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "WordPress REST API Integration and Draft Publishing",
        "description": "Implement WordPress REST API integration to automatically create draft posts with schema markup injection",
        "details": "1. Create WordPressPublisher class:\n   ```python\n   import requests\n   from requests.auth import HTTPBasicAuth\n   import os\n   from typing import Dict, List\n   \n   class WordPressPublisher:\n       def __init__(self):\n           self.site_url = os.getenv('WORDPRESS_URL')\n           self.username = os.getenv('WORDPRESS_USERNAME')\n           self.app_password = os.getenv('WORDPRESS_APP_PASSWORD')\n           self.api_url = f\"{self.site_url}/wp-json/wp/v2\"\n           self.auth = HTTPBasicAuth(self.username, self.app_password)\n       \n       def create_draft_post(\n           self,\n           title: str,\n           content_html: str,\n           schema_markup: Dict,\n           excerpt: str,\n           tags: List[str],\n           primary_keyword: str,\n           source_type: str,\n           source_url: str = None\n       ) -> int:\n           \n           # Inject schema markup into content\n           content_with_schema = self._inject_schema(content_html, schema_markup)\n           \n           # Prepare post data\n           post_data = {\n               'title': title,\n               'content': content_with_schema,\n               'excerpt': excerpt,\n               'status': 'draft',\n               'author': self._get_author_id(),\n               'tags': self._get_or_create_tags(tags),\n               'meta': {\n                   'source_type': source_type,\n                   'source_url': source_url or '',\n                   'primary_keyword': primary_keyword,\n                   'generation_date': datetime.now().isoformat()\n               }\n           }\n           \n           # Create post\n           response = requests.post(\n               f\"{self.api_url}/posts\",\n               json=post_data,\n               auth=self.auth,\n               headers={'Content-Type': 'application/json'}\n           )\n           \n           response.raise_for_status()\n           post_id = response.json()['id']\n           \n           return post_id\n       \n       def _inject_schema(self, html: str, schema: Dict) -> str:\n           \"\"\"Inject JSON-LD schema at end of content\"\"\"\n           import json\n           \n           schema_script = f'<script type=\"application/ld+json\">{json.dumps(schema, indent=2)}</script>'\n           return html + '\\n\\n' + schema_script\n       \n       def _get_author_id(self) -> int:\n           \"\"\"Get WordPress user ID for Evert Calderon\"\"\"\n           response = requests.get(\n               f\"{self.api_url}/users\",\n               auth=self.auth,\n               params={'search': 'evert'}\n           )\n           \n           if response.ok and response.json():\n               return response.json()[0]['id']\n           \n           # Fallback to current user\n           response = requests.get(\n               f\"{self.api_url}/users/me\",\n               auth=self.auth\n           )\n           return response.json()['id']\n       \n       def _get_or_create_tags(self, tag_names: List[str]) -> List[int]:\n           \"\"\"Get or create tags and return their IDs\"\"\"\n           tag_ids = []\n           \n           for tag_name in tag_names:\n               # Search for existing tag\n               response = requests.get(\n                   f\"{self.api_url}/tags\",\n                   auth=self.auth,\n                   params={'search': tag_name}\n               )\n               \n               if response.ok and response.json():\n                   tag_ids.append(response.json()[0]['id'])\n               else:\n                   # Create new tag\n                   create_response = requests.post(\n                       f\"{self.api_url}/tags\",\n                       json={'name': tag_name},\n                       auth=self.auth\n                   )\n                   if create_response.ok:\n                       tag_ids.append(create_response.json()['id'])\n           \n           return tag_ids\n       \n       def verify_post_created(self, post_id: int) -> bool:\n           \"\"\"Verify post was created successfully\"\"\"\n           response = requests.get(\n               f\"{self.api_url}/posts/{post_id}\",\n               auth=self.auth\n           )\n           return response.ok\n   ```\n\n2. Implement retry logic with exponential backoff:\n   ```python\n   def create_draft_post_with_retry(self, *args, **kwargs) -> int:\n       max_retries = 3\n       backoff = 2\n       \n       for attempt in range(max_retries):\n           try:\n               return self.create_draft_post(*args, **kwargs)\n           except requests.exceptions.RequestException as e:\n               if attempt == max_retries - 1:\n                   raise e\n               time.sleep(backoff ** attempt)\n   ```\n\n3. Extract excerpt from blog post:\n   - Use first 150-200 words (direct answer section)\n   - Strip HTML tags\n   - Ensure complete sentences\n\n4. Generate tags from keyword strategy:\n   - Primary keyword\n   - Top 5-10 target keywords\n   - Industry tags (credit repair, debt relief, etc.)",
        "testStrategy": "1. Test WordPress API authentication\n2. Test draft post creation with sample content\n3. Verify post appears in WordPress admin\n4. Verify schema markup displays correctly in post\n5. Test tag creation and assignment\n6. Test author assignment (Evert Calderon)\n7. Test custom fields (source_type, primary_keyword)\n8. Test retry logic with mock API failure\n9. Test excerpt extraction (150-200 words)\n10. Verify post ID is returned and valid\n11. Test with real blog.mesagroupconsulting.com site",
        "priority": "high",
        "dependencies": [
          10,
          11,
          12
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "CLI Interface with Rich Output",
        "description": "Implement command-line interface with argument parsing, progress indicators, and beautiful output using Rich library",
        "details": "1. Create CLI main script (generate.py):\n   ```python\n   import argparse\n   from rich.console import Console\n   from rich.progress import Progress, SpinnerColumn, TextColumn\n   from rich.table import Table\n   from rich.panel import Panel\n   import sys\n   from datetime import datetime\n   \n   console = Console()\n   \n   def main():\n       parser = argparse.ArgumentParser(\n           description='Universal Content Generator - ATP Content Engine',\n           formatter_class=argparse.RawDescriptionHelpFormatter,\n           epilog='''\n   Examples:\n     python generate.py \"https://youtube.com/watch?v=ABC123\"\n     python generate.py \"how to remove late payments from credit report\"\n     python generate.py \"credit card rewards strategies\"\n     python generate.py \"https://nerdwallet.com/article/credit\" --competitor\n     python generate.py \"debt relief\" --skip-wordpress --verbose\n           '''\n       )\n       \n       parser.add_argument('input', help='YouTube URL, ATP question, topic, or competitor URL')\n       parser.add_argument('--type', choices=['youtube', 'atp', 'topic', 'competitor'],\n                          help='Manually specify input type')\n       parser.add_argument('--skip-wordpress', action='store_true',\n                          help=\"Don't create WordPress draft\")\n       parser.add_argument('--skip-images', action='store_true',\n                          help=\"Don't generate image prompts\")\n       parser.add_argument('--output-dir', default='output',\n                          help='Custom output directory')\n       parser.add_argument('--verbose', action='store_true',\n                          help='Detailed logging')\n       parser.add_argument('--competitor', action='store_true',\n                          help='Enable competitor analysis mode')\n       \n       args = parser.parse_args()\n       \n       # Display header\n       console.print(Panel.fit(\n           \"[bold cyan]Universal Content Generator[/bold cyan]\\n\"\n           \"[dim]ATP Content Engine v1.0[/dim]\",\n           border_style=\"cyan\"\n       ))\n       \n       start_time = datetime.now()\n       \n       try:\n           with Progress(\n               SpinnerColumn(),\n               TextColumn(\"[progress.description]{task.description}\"),\n               console=console\n           ) as progress:\n               \n               # Step 1: Input processing\n               task1 = progress.add_task(\"[cyan]Processing input...\", total=None)\n               input_processor = InputProcessor()\n               normalized_data = input_processor.process(args.input, args.type)\n               progress.update(task1, completed=True)\n               console.print(\" Input processed:\", normalized_data.input_type, style=\"green\")\n               \n               # Step 2: Keyword research\n               task2 = progress.add_task(\"[cyan]Researching keywords...\", total=None)\n               keyword_engine = KeywordEngine()\n               keyword_strategy = keyword_engine.analyze(normalized_data.primary_topic)\n               progress.update(task2, completed=True)\n               console.print(f\" Keywords analyzed: {len(keyword_strategy.target_keywords)} keywords\", style=\"green\")\n               \n               # Step 3: Multi-source research\n               task3 = progress.add_task(\"[cyan]Researching from multiple sources...\", total=None)\n               research_engine = ResearchEngine()\n               research_data = research_engine.research(normalized_data, keyword_strategy)\n               progress.update(task3, completed=True)\n               console.print(f\" Research complete: {len(research_data.all_sources)} sources\", style=\"green\")\n               \n               # Step 4: Content generation\n               task4 = progress.add_task(\"[cyan]Generating content...\", total=None)\n               content_generator = ContentGenerator()\n               generated_content = content_generator.generate_all_content(research_data, keyword_strategy)\n               progress.update(task4, completed=True)\n               console.print(\" Content generated\", style=\"green\")\n               \n               # Step 5: Schema generation\n               task5 = progress.add_task(\"[cyan]Generating schema markup...\", total=None)\n               schema_generator = SchemaGenerator()\n               schema = schema_generator.generate_schema(\n                   keyword_strategy.recommended_schema,\n                   generated_content,\n                   keyword_strategy,\n                   research_data\n               )\n               progress.update(task5, completed=True)\n               console.print(\" Schema markup generated\", style=\"green\")\n               \n               # Step 6: Save files\n               task6 = progress.add_task(\"[cyan]Saving files...\", total=None)\n               output_handler = OutputHandler(args.output_dir)\n               output_dir = output_handler.save_content_package(\n                   normalized_data.primary_topic,\n                   generated_content,\n                   keyword_strategy,\n                   research_data,\n                   schema,\n                   normalized_data.input_type,\n                   normalized_data.source_url\n               )\n               progress.update(task6, completed=True)\n               console.print(f\" Files saved to: {output_dir}\", style=\"green\")\n               \n               # Step 7: WordPress publishing (optional)\n               wordpress_post_id = None\n               if not args.skip_wordpress:\n                   task7 = progress.add_task(\"[cyan]Creating WordPress draft...\", total=None)\n                   wp_publisher = WordPressPublisher()\n                   wordpress_post_id = wp_publisher.create_draft_post(\n                       title=keyword_strategy.primary_keyword.keyword,\n                       content_html=generated_content.blog_post_html,\n                       schema_markup=schema,\n                       excerpt=generated_content.meta_description,\n                       tags=[k.keyword for k in keyword_strategy.target_keywords[:10]],\n                       primary_keyword=keyword_strategy.primary_keyword.keyword,\n                       source_type=normalized_data.input_type,\n                       source_url=normalized_data.source_url\n                   )\n                   progress.update(task7, completed=True)\n                   console.print(f\" WordPress draft created: Post ID {wordpress_post_id}\", style=\"green\")\n           \n           # Display summary\n           end_time = datetime.now()\n           duration = (end_time - start_time).total_seconds()\n           \n           display_summary(\n               normalized_data,\n               keyword_strategy,\n               output_dir,\n               wordpress_post_id,\n               duration\n           )\n           \n       except Exception as e:\n           console.print(f\"\\n[bold red]Error:[/bold red] {str(e)}\")\n           if args.verbose:\n               console.print_exception()\n           sys.exit(1)\n   \n   def display_summary(normalized_data, keyword_strategy, output_dir, wp_post_id, duration):\n       table = Table(title=\"Generation Summary\", show_header=True, header_style=\"bold cyan\")\n       table.add_column(\"Metric\", style=\"cyan\")\n       table.add_column(\"Value\", style=\"green\")\n       \n       table.add_row(\"Input Type\", normalized_data.input_type)\n       table.add_row(\"Primary Keyword\", keyword_strategy.primary_keyword.keyword)\n       table.add_row(\"Search Volume\", str(keyword_strategy.primary_keyword.search_volume))\n       table.add_row(\"Target Keywords\", str(len(keyword_strategy.target_keywords)))\n       table.add_row(\"Schema Type\", keyword_strategy.recommended_schema)\n       table.add_row(\"Output Directory\", str(output_dir))\n       if wp_post_id:\n           table.add_row(\"WordPress Post ID\", str(wp_post_id))\n       table.add_row(\"Generation Time\", f\"{duration:.1f} seconds\")\n       table.add_row(\"Estimated Cost\", \"$1.50\")  # Placeholder\n       \n       console.print(\"\\n\")\n       console.print(table)\n       console.print(\"\\n[bold green] Content generation complete![/bold green]\\n\")\n   \n   if __name__ == '__main__':\n       main()\n   ```\n\n2. Implement error handling with clear messages:\n   - Invalid input format\n   - API failures\n   - File system errors\n   - Network timeouts\n\n3. Add logging configuration:\n   - Console logging with Rich\n   - File logging to logs/atp-generator-YYYY-MM-DD.log\n   - Different log levels (DEBUG, INFO, WARNING, ERROR)",
        "testStrategy": "1. Test CLI with all 4 input types\n2. Test argument parsing (--type, --skip-wordpress, etc.)\n3. Test progress indicators display correctly\n4. Test summary table displays all metrics\n5. Test error handling (invalid input, API failure)\n6. Test verbose mode shows detailed logs\n7. Test --skip-wordpress flag\n8. Test --output-dir custom directory\n9. Test exit codes (0 for success, 1 for error)\n10. Test on Windows, Mac, and Linux\n11. Test help message (--help)",
        "priority": "high",
        "dependencies": [
          2,
          5,
          9,
          10,
          11,
          12,
          13
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Quality Validation and AEO/GEO Compliance Checker",
        "description": "Implement automated quality validation, AEO/GEO compliance checking, and completeness scoring with actionable feedback",
        "details": "1. Create QualityValidator class:\n   ```python\n   from typing import Dict, List, Tuple\n   import re\n   from bs4 import BeautifulSoup\n   \n   class QualityValidator:\n       def validate_blog_post(self, html: str, keyword_strategy: KeywordStrategy) -> ValidationResult:\n           soup = BeautifulSoup(html, 'html.parser')\n           text = soup.get_text()\n           \n           checks = []\n           \n           # Word count check\n           word_count = len(text.split())\n           checks.append(self._check_word_count(word_count, 1500, 2500))\n           \n           # Keyword density check\n           primary_keyword = keyword_strategy.primary_keyword.keyword.lower()\n           keyword_count = text.lower().count(primary_keyword)\n           keyword_density = (keyword_count / word_count) * 100\n           checks.append(self._check_keyword_density(keyword_density, 1.0, 2.0))\n           \n           # Structure checks\n           h2_tags = soup.find_all('h2')\n           checks.append(self._check_h2_count(len(h2_tags), min_count=3))\n           \n           # Question-based headers\n           question_h2s = [h2 for h2 in h2_tags if '?' in h2.get_text()]\n           checks.append(self._check_question_headers(len(question_h2s), min_count=3))\n           \n           # Lists check\n           lists = soup.find_all(['ul', 'ol'])\n           checks.append(self._check_lists(len(lists), min_count=2))\n           \n           # Direct answer check (first 200 words)\n           first_200_words = ' '.join(text.split()[:200])\n           checks.append(self._check_direct_answer(first_200_words, primary_keyword))\n           \n           # Citation check\n           links = soup.find_all('a', href=True)\n           authoritative_links = [l for l in links if any(domain in l['href'] for domain in ['.gov', 'cfpb', 'ftc'])]\n           checks.append(self._check_citations(len(authoritative_links), min_count=3))\n           \n           # Readability check (Flesch reading ease)\n           readability_score = self._calculate_readability(text)\n           checks.append(self._check_readability(readability_score, min_score=60))\n           \n           # Calculate overall score\n           score = self._calculate_score(checks)\n           \n           return ValidationResult(\n               score=score,\n               checks=checks,\n               passed=score >= 80,\n               suggestions=self._generate_suggestions(checks)\n           )\n       \n       def validate_youtube_script(self, script: str) -> ValidationResult:\n           checks = []\n           \n           # Word count check\n           word_count = len(script.split())\n           checks.append(self._check_word_count(word_count, 1750, 2500))\n           \n           # Hook check (first 30 seconds / ~75 words)\n           first_75_words = ' '.join(script.split()[:75])\n           checks.append(self._check_hook_present(first_75_words))\n           \n           # CTA check\n           cta_count = script.lower().count('[cta') + script.lower().count('call to action')\n           checks.append(self._check_cta_count(cta_count, min_count=3))\n           \n           # Production notes check\n           has_broll = '[b-roll' in script.lower()\n           has_timestamps = bool(re.search(r'\\[\\d{2}:\\d{2}\\]', script))\n           checks.append(self._check_production_notes(has_broll, has_timestamps))\n           \n           score = self._calculate_score(checks)\n           \n           return ValidationResult(\n               score=score,\n               checks=checks,\n               passed=score >= 80,\n               suggestions=self._generate_suggestions(checks)\n           )\n       \n       def validate_aeo_geo_compliance(self, html: str, keyword_strategy: KeywordStrategy) -> AEOGEOResult:\n           soup = BeautifulSoup(html, 'html.parser')\n           text = soup.get_text()\n           \n           checklist = {\n               'direct_answer_first_200': self._has_direct_answer(text, keyword_strategy.primary_keyword.keyword),\n               'question_based_h2s': len([h2 for h2 in soup.find_all('h2') if '?' in h2.get_text()]) >= 3,\n               'lists_present': len(soup.find_all(['ul', 'ol'])) >= 2,\n               'authoritative_citations': len([l for l in soup.find_all('a', href=True) if '.gov' in l['href']]) >= 3,\n               'active_voice': self._check_active_voice_percentage(text) >= 80,\n               'no_marketing_fluff': self._check_no_fluff(text),\n               'related_questions_answered': len([h2 for h2 in soup.find_all('h2') if '?' in h2.get_text()]) >= 3,\n               'schema_markup_ready': True,  # Checked separately\n               'author_bio_present': 'evert calderon' in text.lower() or 'mesa group' in text.lower()\n           }\n           \n           passed_count = sum(checklist.values())\n           total_count = len(checklist)\n           compliance_percentage = (passed_count / total_count) * 100\n           \n           return AEOGEOResult(\n               checklist=checklist,\n               compliance_percentage=compliance_percentage,\n               passed=compliance_percentage >= 80,\n               recommendations=self._generate_aeo_recommendations(checklist)\n           )\n       \n       def _calculate_readability(self, text: str) -> float:\n           \"\"\"Calculate Flesch Reading Ease score\"\"\"\n           sentences = text.count('.') + text.count('!') + text.count('?')\n           words = len(text.split())\n           syllables = self._count_syllables(text)\n           \n           if sentences == 0 or words == 0:\n               return 0\n           \n           score = 206.835 - 1.015 * (words / sentences) - 84.6 * (syllables / words)\n           return max(0, min(100, score))\n       \n       def _count_syllables(self, text: str) -> int:\n           \"\"\"Approximate syllable count\"\"\"\n           words = text.lower().split()\n           syllable_count = 0\n           for word in words:\n               syllable_count += max(1, len(re.findall(r'[aeiou]+', word)))\n           return syllable_count\n       \n       def _check_active_voice_percentage(self, text: str) -> float:\n           \"\"\"Estimate active voice percentage (simplified)\"\"\"\n           # Simplified check - count passive indicators\n           passive_indicators = ['was', 'were', 'been', 'being', 'is', 'are']\n           words = text.lower().split()\n           passive_count = sum(words.count(indicator) for indicator in passive_indicators)\n           active_percentage = max(0, 100 - (passive_count / len(words) * 100))\n           return active_percentage\n       \n       def _calculate_score(self, checks: List[Dict]) -> int:\n           \"\"\"Calculate overall quality score 0-100\"\"\"\n           if not checks:\n               return 0\n           passed = sum(1 for check in checks if check['passed'])\n           return int((passed / len(checks)) * 100)\n   \n   class ValidationResult(BaseModel):\n       score: int\n       checks: List[Dict]\n       passed: bool\n       suggestions: List[str]\n   \n   class AEOGEOResult(BaseModel):\n       checklist: Dict[str, bool]\n       compliance_percentage: float\n       passed: bool\n       recommendations: List[str]\n   ```\n\n2. Integrate validation into generation pipeline:\n   - Run validation after content generation\n   - Display validation results in CLI\n   - Option to regenerate if score < 70\n\n3. Create validation report:\n   - Save validation results to output directory\n   - Include detailed breakdown of checks\n   - Provide actionable recommendations",
        "testStrategy": "1. Test blog post validation with sample content\n2. Test word count check (pass and fail cases)\n3. Test keyword density check\n4. Test structure checks (H2 count, lists)\n5. Test AEO/GEO compliance checklist\n6. Test readability calculation\n7. Test active voice percentage estimation\n8. Test YouTube script validation\n9. Test completeness scoring (0-100)\n10. Verify suggestions are actionable\n11. Test with real generated content\n12. Verify validation completes in <5 seconds",
        "priority": "medium",
        "dependencies": [
          10,
          11
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2026-02-12T00:54:32.700Z",
      "updated": "2026-02-12T00:54:32.701Z",
      "description": "Tasks for content-generator context"
    }
  }
}